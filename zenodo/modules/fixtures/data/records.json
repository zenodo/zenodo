[
  {
    "files": [
      "CERN_openlab_Parin_Porecha.pdf"
    ], 
    "metadata": {
      "title": "Deploying ImageFactory", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Porecha, Parin ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Fernandez Alvarez, Luis", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "closed", 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>The common practice between OpenStack users is to manually install a base operating system,&nbsp;boot it up, install packages, add necessary configuration and then snapshot it for later use. Much&nbsp;of this can be automated using kickstart files, Puppet, etc. but it&rsquo;s still a tedious process.&nbsp;That&rsquo;s where Image Factory comes&nbsp;into play. It allows you to describe your virtual image (the&nbsp;operating system, architecture, installed packages, etc.) and have it uploaded to&nbsp;various&nbsp;cloud&nbsp;providers (such as EC2, oVirt or OpenStack). This could be&nbsp;useful to the OpenStack users&nbsp;even without all the cross-cloud features.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Nitin_Agarwal.pdf"
    ], 
    "metadata": {
      "title": "Docker on OpenStack", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "access_conditions": "Please ask the author(s) to know more about the access conditions", 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Agarwal, Nitin ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Moreira, Belmiro", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "restricted", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>CERN is establishing a large scale private cloud based on OpenStack as part of the expansion of the computing infrastructure for storing the data coming out of the Large Hadron Collider (LHC) experiments. As the data coming out of the detectors is increasing continuously that needs to be stored in the data center, we need more physical resources (more money) and since Virtual machines takes lot of CPU and memory overhead and minutes for creating the images, booting up and for snapshotting as well. So here comes the solution to use Docker containers. Docker is an open platform to build, ship and run distributed applications. Docker being a container based virtualisation framework makes use of LXC. Docker containers are lightweight and fast and docker makes use of Union File System which makes it unique. Docker comes with the Docker Index/ Hub where you can store and share the docker images. This project involves the understanding of Docker and docker containers in detail, deployment of private Docker Registry as well as the integration of docker with Openstack to enable the Nova compute service to use the docker API as compute driver instead of the libvirt API.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>At CERN, with the ever increasing amount of data coming out of the detectors that needs to be stored in the data center, new ways are sought to help analyze and store this data as well as help researchers perform their own experiments. To help offer solutions to such problems, CERN has employed the use of cloud computing and in particular OpenStack\u037e an open source and scalable platform for building public and private clouds. OpenStack is used to view, create, and manage resources in a cloud and automate the tasks. Compute nodes form the resource core of the OpenStack Compute cloud, providing the processing, memory, network and storage resources to run instances. As the data is increasing continuously around 50 PB/sec and about 5 PB/day of data that needs to be stored, CERN is looking for new ways to utilise the hardware resources of the data center more efficiently. In this project we outline and document the integration of Docker with the Nova compute service of OpenStack (Devstack, Packstack), deployment of private Docker Registry at CERN for pushing and pulling the docker images. To allow the Nova compute service to use to the Docker API as compute driver instead of the Libvirt driver and to allow nova to boot the docker images, we need to store the docker images in glance that acts as an independent docker registry after configuration. In this report, we describe about docker, its basics and importance of docker containers in comparison to virtual machines, steps for deploying and configuring the private Docker Registry at CERN and steps for configuring the Nova to use docker driver in Devstack on Ubuntu cloud image and Packstack on RHEL 7.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Sneha.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>SQLPlotter is a C++ macro written using ROOT classes which has previously&nbsp;been developed to&nbsp;allow the possibility of making histograms from the&nbsp;results of SQL-queries running on physics&nbsp;analysis data stored in a relational&nbsp;database.&nbsp;This project is aimed at developing a web &ndash; interface for this&nbsp;SQLPlotter with a ROOTinstallation&nbsp;running locally on the web-server,&nbsp;eliminating the requirement of learning ROOT in&nbsp;depth and providing the&nbsp;users with an easy to use interface that can be accessed&nbsp;anytime,&nbsp;anywhere&nbsp;to do physics analysis inside a database.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>As part of the CERN openlab collaboration a study was made into the possibility of performing analysis of the data collected by the experiments at the Large Hadron Collider (LHC) [1] through SQL-queries on data stored in a relational database[2]. To show how SQL-queries can be used to perform basic physics analysis tasks, a C++ macro called &ldquo;SQLPlotter&rdquo; was developed to make ROOT-plots using the output-data from SQL-queries. This project, a web-interface to SQLPlotter basically addresses two major objectives. One objective is to make particle physics analysis more accessible, especially to students who do not have the software skills currently needed to analyse LHC data. Another important aim is to demonstrate the underlying principle of SQLPlotter that SQL queries can be used to perform complex analysis tasks. The web-interface has been implemented using basic web-technologies, including PHP, HTML5 and JavaScript. In future, this web-interface can be envisaged to be brought into production as an educational tool for students interested in physics analysis.</p>", 
      "title": "SQLPlotter : Developing a web-interface for a physics analysis database", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Sneha", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Limper, Maaike", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Hana_Wurzelova.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons CCZero", 
        "url": "http://www.opendefinition.org/licenses/cc-zero", 
        "id": "cc-zero"
      }, 
      "title": "EOS Monitoring and Analytics Tools", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Wurzelova, Hana ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Mascetti, Luca ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>The IT DSS group at CERN runs and evaluates innovative cloud storage&nbsp;technologies for their&nbsp;application to big data problems in high-energy&nbsp;physics research. One of the main storage&nbsp;systems is EOS, a multi&nbsp;petabyte disk storage built from commodity hardware heavily used by&nbsp;LHC&nbsp;and non-LHC experiments, primarily for physics data.&nbsp;In the scope of a&nbsp;common monitoring framework for our cloud storage services and in order to&nbsp;improve the analytics, the manageability and the user interface, this project&rsquo;s&nbsp;aim was to:</p>\n\n<ul>\n\t<li>&nbsp;implement a probing system to check storage health and main KPI</li>\n\t<li>implement features for the web visualization of storage KPIs</li>\n\t<li>investigate the integration of other monitoring within the framework</li>\n\t<li>compare different solution of storage monitoring and analytic tools</li>\n</ul>\n\n<p><strong>Abstract</strong></p>\n\n<p>The aim of this openlab project was to improve user experience of EOS, a disk&nbsp;based data storage&nbsp;system used by LHC and non-LHC users. The online&nbsp;monitoring systems for EOS are various and&nbsp;this project main focus was on&nbsp;improving EOS Cockpit structure and functionalities and&nbsp;simplifying SLS&nbsp;probing system. The EOS Cockpit structure was changes according to users&rsquo;&nbsp;requirements, and new features were implemented. The SLS probing script&nbsp;was significantly&nbsp;simplified and adapted to the next generation tools used&nbsp;for displaying service levels.</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-JorgeCosta.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>PROJECT SPECIFICATION&nbsp;</strong></p>\n\n<p>RapidIO (http://rapidio.org/) technology is a package-switched high-performance fabric, which has been under active development since 1997. The technology is used in all 4G/LTE basestations worldwide. RapidIO is often used in embedded systems that require high reliability, low latency and deterministic operations but there may now be an opportunity to take the same value proposition to more mainstream data processing, which is the underlying motivation for this Project. The objective for the Openlab collaboration with IDT is to test and evaluate the suitability of IDT&rsquo;s low-latency RapidIO interconnect technology for a number of use-cases ranging from LHC Data Acquisition and Triggering to Data analytics for the data center monitoring and operations.&nbsp;</p>", 
      "title": "RAPIDIO USAGE IN A BIG DATA ENVIRONMENT", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Costa, Jorge", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Barring, Olof", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "TheOverheadOfProfilingUsingPMUhardwareCounters.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution", 
        "url": "http://www.opendefinition.org/licenses/cc-by", 
        "id": "cc-by"
      }, 
      "title": "The overhead of profiling using PMU hardware counters", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "PMU", 
        "Performance Monitoring Unit", 
        "counter", 
        "processor"
      ], 
      "publication_date": "2014-07-08", 
      "creators": [
        {
          "name": "Nowak, Andrzej", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Bitzes, Georgios", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p>Run-time profiling of executable binaries can offer valuable insight into the performance characteristics and behaviour of a program. Some methods, such as instrumentation, are invasive and involve modifications of the profiled binary. This can significantly impact performance, to the point that an instrumented binary runs many times slower than the original. The Performance Monitoring Unit found in many modern processors offers the possibility of low-overhead profiling through a plethora of performance events. In this report, we investigate and quantify this overhead for a variety of tests and configurations, using the &ldquo;perf&rdquo; tool of the Linux kernel. Results for four main usage modes of the PMU are included: counting, sampling, PEBS events, and Last Branch Record (LBR).</p>"
    }
  }, 
  {
    "files": [
      "CERNopenlabWhitepaperonFutureICTChallengesinScientificResearchV1.3.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>This whitepaper describes the major IT challenges in scientific research at CERN and several other European and international research laboratories and projects. Each challenge is exemplified through a set of concrete use cases drawn from the requirements of large-scale scientific programs. The paper is based on contributions from many researchers and IT experts of the participating laboratories and also input from the existing CERN openlab industrial sponsors. The views expressed in this document are those of the individual contributors and do not necessarily reflect the view of their organisations and/or affiliates.</p>", 
      "title": "CERN openlab Whitepaper on Future IT Challenges in Scientific Research", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab", 
        "IT", 
        "Data acquisition", 
        "Computing platforms", 
        "Cloud computing", 
        "Data storage", 
        "Networks", 
        "Data analytics"
      ], 
      "publication_date": "2014-05-21", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Gaillard, Melissa", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Purcell, Andrew", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "HEPTech_Big_Data_Keynote_20150330.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Keynote presentation at the HEPTech Conference on Big Data, Budapest, 30 March 2015. A personal definition of Big Data, its technological challenges and impact on society.</p>", 
      "title": "Big Data Challenges - Power and Responsibilities", 
      "communities": [], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN openlab", 
        "Big Data", 
        "IoT"
      ], 
      "publication_date": "2015-03-30", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "reportJakubKvita_for_website.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>CERN runs a large scale OpenStack based cloud on over 4,200 hypervisors to provide computing resources for users on demand. Critical application data can be stored on reliable disk volumes.</p>\n\n<p>The project would involve investigation of solutions for long term archiving of contents and defining the necessary large scale deployment tools using Puppet along with performance tuning for production usage.</p>\n\n<p>The student will gain understanding of cloud technologies, experience with OpenStack and Puppet along with storage technologies such as Ceph and TSM.</p>\n\n<p>The work would also involve collaboration with large open source communities.&nbsp;</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>This report is a summary of solutions for archivation of Cinder volumes and user-driven creation of virtual volumes backups. Solutions are based and evaluated on current CERN private cloud status and currently used environments and tools.</p>\n\n<p>The explored solutions include use of TSM - tape storage and two different clusters of Ceph in two different geographical locations(Meyrin and Wigner).&nbsp;</p>", 
      "title": "Archiving OpenStack Cloud Volumes", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Kvita, Jakub", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Bukowiec, Sebastian", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-AnirudhaBose.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>This document introduces a new data ingestion framework called HLoader, built around Apache Sqoop to perform data ingestion jobs between RDBMS and Hadoop Distributed File System (HDFS). The HLoader framework deployed as a service inside CERN will be used for CMS Data Popularity ingestion into Hadoop clusters. HLoader could also be used for similar use cases like CMS and ATLAS Job Monitoring, ACCLOG databases, etc. The first part of the report describes the architectural details of HLoader, giving some background information about Apache Sqoop. The rest of the report focuses on the HLoader programming API, and is meant to be an entry point for developers describing how HLoader works, and possible directions of extending the framework in future.&nbsp;</p>", 
      "title": "CMS Data-Services Ingestion into CERN\u2019s Hadoop Big Data Analytics Infrastructure", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Bose, Anirudha", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Giordano, Domenico", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Romero Marin, Antonio", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Martin Marquez, Manuel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-EstefaniaSerrano.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>Millepede is a multi-threaded detector alignment and calibration software based on the Linear Least Squares Fit algorithm for fitting a large number of parameters (5M+). Developed at DESY, the application is used in many HEP sites, including CERN. Due to computational and memory complexity, the application uses an in-house principle of submatrix partitioning. While this is the way to make the computation feasible, it is not possible to deliver uncertainty for every estimated parameter. The project concerns characterizing the application in terms of parallelization efficiency, including the multi-threading and vectorization aspects. &nbsp;The project was also ported to Intel Xeon Phi, which allowed conducting a performance comparison between Xeon and Xeon Phi.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>Optimization of a scientific application is not an easy task. It requires a broad knowledge and following a multiple-step methodology. In this work we have characterized and optimized a detector alignment software called Millepede II. We have focused on different performance levels: vectorization, parallelism, memory distribution. Also, the software was ported to Xeon Phi. For the characterization of the application we have used several tools including Intel Advisor and Intel VTune Amplifier.</p>\n\n<p>In this paper we show that there is some room for optimization without introducing massive modifications to the code. We obtain a speed-up of 15% by introducing changes in the code to ease the vectorization and by choosing the right scheduling for each parallel section of the code.</p>\n\n<p>Finally, we run the software on Xeon Phi, obtaining not satisfactory results due to the lack of adaptation of the software to the card&rsquo;s hardware.</p>\n\n<p>&nbsp;</p>", 
      "title": "Optimization Studies of Millepede - a Detector Alignment Application", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Serrano, Estefania", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Szostek, Pawe\u0142", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-EnricoGuiraud.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>ROOT is a C++ library developed by CERN for data analysis and plotting.</p>\n\n<p>PROOF is a multi-process framework to run ROOT&nbsp; data analytics in parallel on distributed resources. It implements a 3-tier client-master-workers architecture, with the master in charge of dynamic work distribution and collection of the results.</p>\n\n<p>PROOF-Lite is a version of PROOF optimized for multi-core machines. It has found much success in the HEP community because of its direct and simple way of exploit multi-cores. However, it suffers from some difficulties coming from the fact that it inherits the setup technology from PROOF. In particular, setting up the environment of the workers requires the manual replication of the client configuration, a fragile process open to inconsistencies and failures.</p>\n\n<p>In this project the student will prototype the possibility to create the workers from the client using process forking just before the execution of the query, so eliminating the need of any additional configuration of the workers and taking advantage of copy-on-write system feature.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>In this report we outline the results and the products of our <strong>investigation of ROOT multi-processing capabilities</strong>: not only we showed that <strong>it is possible to fork a ROOT session</strong> running in Linux environment, but we also built a <strong>framework</strong> that allows to easily exploit this capability to build <strong>parallel applications</strong> based on a client-worker architecture.</p>\n\n<p>Moreover, using this framework as a foundation, we built a <strong>new ROOT feature, the </strong><strong>Map</strong><strong> function</strong>, inspired by python&rsquo;s pool.map: this function allows to execute the same task many times in parallel on different arguments, giving users an easy and lightweight access to multi-processing.</p>\n\n<p>Section 1 is dedicated to a brief explanation of the current approach to multi-processing in ROOT, namely the PROOF and PROOF-Lite facilities.<br />\nSection 2 describes our new approach, its advantages and issues and some implementation details.<br />\nSection 3 describes the Map application, a few usage examples, some implementation details and the analysis of its performance.<br />\nSection 4 outlines some of the possible future developments of the work done so far.</p>", 
      "title": "Enhancements to Multiprocessing in ROOT", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Guiraud, Enrico", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Ganis, Gerardo ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-MufutauAkuruyejo.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>With the introduction of Puppet configuring machines hosting Oracle databases managed by IT-DB Group of the European Organization for Nuclear Research (CERN), it is now much easier to apply any changes and perform the upgrades. Doing so on production environments is always a risk, which has to be addressed, by creating proper test environment. With Oracle Real Application Testing and related features it is currently possible to thoroughly test impact of any change, before implementing it on production and avoid virtually all problems.</p>\n\n<p>The aim of the project is to add a new kind of testing i.e. the Oracle Real Application Testing (RAT) to an existing framework &ndash; DBTest. With the addition of this module, the DBTest framework would be more robust and be more able to detect performance issues in databases due to modifications. The author within the time frame didn&rsquo;t complete the RAT module but has written a significant part of the module. Also, the author made some improvements to the existing framework. Some of the improvements are starting a database before connecting to it, making the reporting of the framework easier to read and also enhancing the error messages.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>Changes occur to production environments regularly and they pose a risk to production. This could be patches to the underlying kernel, migrating to another distribution or an upgrade to the Operating System version. It could also be parameter changes to the database or a change in the vendor. Sometimes, this leads to degradation in the performance of the database. The author extended a framework for database testing by including a module that utilizes a testing tool provided by Oracle &ndash; Real Application Testing. The Real Application Testing (RAT) allows workload of a database to be captured and replayed on a test environment. This document explains the Oracle Real Application Testing then gives a brief overview of DBTest &ndash; a framework that automates testing of databases. After this, the author presents how to use this tool to help detect performance changes in databases.</p>\n\n<p>The result is a tool that makes databases performance testing easy. The author made improvements to the original framework and also wrote the rudimentary code for the Real Application Testing framework. Hence, the original framework, DBTest can now also start databases before connecting to them amongst other improvements. It is the aim of the author that subsequently, the Real Application Testing module can be completed.</p>", 
      "title": "Continuous Integrated Testing of Oracle Databases on CERN Agile Infrastructure", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Akuruyejo, Mufutau", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Skorupinski, Szymon", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-EmmanouilKatsomallos.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>Testing and further developing an infrastructure based on CernVM that enables launching jobs on volunteer nodes, cluster nodes and commercial cloud nodes. This technology will support a CERN educational game called Virtual Atom Smasher.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>Due to hardware and parallelization constraints, distributing resource demanding computational tasks and assigning them to a grid of commercial or volunteer private nodes is a one-way solution. The cloud is undeniably the model that will, if it has not already, dominate in the field of computing. Numerous new cloud services appear constantly in the literature and the ones that were once state of the art are currently ported there. It is pretty much straight forward that the exploitation of such practices is critical for any notable effort. The purpose of this project was to combine the aforementioned entities, take advantage of top notch technologies and motivate citizens to participate in mass computing campaigns by offering the resources that they have in their possession.&nbsp;</p>", 
      "title": "Combining Grid, Cloud and Volunteer Computing", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Katsomallos, Emmanouil", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Charalampidis, Ioannis", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-ukaszChrzaszcz.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>First version of Invenio considered albums as a first-class citizen of a system while treating photos as a subrecord of an album limiting user&rsquo;s ability to add extra metadata to single pictures or index/search them. Additionally, management issues came into play, when user wanted to place one photo in multiple albums the only way to achieve that was to upload it twice, therefore introducing high redundancy.</p>\n\n<p>The goal of photo albums changes in Invenio 2 is to solve aforementioned issues, by extracting pictures from albums, creating new records out of them and translating them to JSON from previous marc21 format to gain even more flexibility.</p>", 
      "title": "Photo Albums in Invenio 2.x", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Chrz\u0105szcz, \u0141ukasz", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Marian, Ludmila", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-TomVanSteenkiste.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>The Parameter classes of the ALICE/FAIR (ALFA) software framework contain and manage all the numerical information needed to process the data. In order to analyse the raw or simulated data, several numerical parameters are needed, such as, calibration/digitization parameters or geometry positions of detectors. One common characteristic to most of these parameters is that they will go through several different versions corresponding, for example, to changes in the detectors&rsquo; definition or any other condition. This makes it necessary to have a parameter repository with a well-defined versioning system. The runtime database (Parameter manager in ALFA) is such a repository.&nbsp; It knows about&nbsp; all parameter containers needed for the actual analysis. The containers can be initialized automatically from one or more inputs, and written out to one output. Possible inputs/output mechanisms are ROOT files or ASCII files.</p>\n\n<p>In this project a key-value database will be investigated as an optional IO for the runtime database.</p>\n\n<p>Abstract</p>\n\n<p>In this project, several key-value databases are compared for their performance to implement them into the ALFA framework. As the research shows that a RAMCloud key-value database is not suited for this project, a deep research is done into Riak instead. The case-study compares read vs write latency, optimal simulation sample size, different storage backends, object size influence, cluster size influence, different consistency settings and there performance impact, the impact of adding security, the overhead of using a Java tool and the availability and fault tolerance of Riak. All these measurements are discussed taking into account certain difficulties of simulating a key value database. This gives us a document showing the impact of certain design decisions in implementing a key-value store and will allow developers for future projects to easily ascertain how changes in the database will impact performance and how to easily use a tool developed during this project to make exact measurements.</p>", 
      "title": "Integration of Key-Value Database in the Parameter Management System of the ALFA Framework", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Van Steenkiste, Tom", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Buncic, Predrag", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-GabriellaAzzopardi.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>This project involves the following:</p>\n\n<ol>\n\t<li>\n\t<p>Data Analytics as a Service - Providing a way for users to write their own Data Analytics algorithms in R through the use of Jupyter. This will allow them to easily run and share their code, data and results.</p>\n\t</li>\n\t<li>\n\t<p>Scale out data analytics algorithm using Docker - Parallelizing the algorithm across a cluster on Openstack by dividing the task over multiple nodes to execution time.</p>\n\t</li>\n</ol>\n\n<p>Once completed, this project will provide users with the necessary tools and infrastructure to be able to perform Data Analytics themselves on their data as well as view their results in a straightforward manner.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>The control systems needed to run the Large Hadron Collider (LHC), its injector accelerators and their infrastructure generate massive amounts of data. This data can be used to optimize the control systems, and provide meaningful information to the machines operators and experts. At present, algorithms perform Data Analytics on over 3000 signals each day, and this number is only increasing. Performing such a large amount of computations is time consuming, especially when run on a single machine. Therefore it is through this project that we aim to search for a means of parallelizing the execution of such algorithms. The proposed solution makes use of Docker which allows for straightforward scalability. Results show that scaling up the system does indeed decrease the execution time required.&nbsp;</p>", 
      "title": "Statistical Reports and Data Analytics with Distributed Computing", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Azzopardi, Gabriella", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Voitier, Axel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Maria Tilaro, Filippo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-TobiasKappe.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>The objective of this project is to investigate the possibility of using persistent memory to store the EOS namespace. To this end, a hashtable amenable to transactional use is necessary. The hashtable needs to be benchmarked and integrated with the EOS source code. Furthermore, the hashtable should be validated on persistent memory.</p>\n\n<p>Abstract</p>\n\n<p>EOS[1] provides fast and reliable disk-only storage for data produced by the LHC experiments. In order to ensure fast access, EOS keeps a representation of the namespace in RAM along with a change-log file on disk. As a consequence, restoring the namespace from disk after a restart or a crash can take a relatively long time. Migration of the namespace to persistent memory (non-volatile RAM or NVRAM) will ensure persistence of data even in the event of a sudden power cut, as well as a considerable improvement on boot-up time. However, this migration requires that changes to the memory are done in a <em>transactional</em> fashion; in the event of a crash, we would like to recover with a consistent view of the namespace.</p>\n\n<p>We present a hashtable that can be used to store contents persistently and transactionally, for use with the Mnemosyne[2] toolchain. To benchmark and validate this hashtable, an extensible benchmarking tool was written. We show that, outside Mnemosyne, our hashtable has a performance similar to the implementation currently in use. We furthermore integrate our own hashtable into the EOS code base.</p>", 
      "title": "Towards EOS Namespace Persistence in NVRAM: Hashtable Benchmarks", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Kapp\u00e9, Tobias", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Alin Sindrilaru, Elvin", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "D\u00fcllmann, Dirk", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-Siddha_Ganju.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>The goal of this openlab summer student project is to analyse Apache Spark as a framework for the big data analytics framework of CERN. It utilizes MLlib and Spark Streaming along with Python and its libraries such as scikit-learn and scipy. The objective was to determine if the metadata of CMS can be analysed efficiently, in terms of CPU usage and time for completion of the job using Apache Spark. Apache Spark is a framework providing speedy and parallel processing of distributed data in real time. Additionally it provides powerful cache and persistence capabilities. Because of these features Apache Spark is applied to data analytics problems. Components of Spark like Spark Streaming and MLlib (Spark native machine learning library) make analysis possible.</p>\n\n<p>Software Specifications:</p>\n\n<ol>\n\t<li>\n\t<p>Apache Spark Release 1.4.0</p>\n\t</li>\n\t<li>\n\t<p>Python 2.7.5</p>\n\n\t<ol>\n\t\t<li>\n\t\t<p>scikit-learn package i. ensemble</p>\n\n\t\t<p>ii. cross_validation iii. neighbors<br />\n\t\tiv. decomposition</p>\n\t\t</li>\n\t\t<li>\n\t\t<p>pandas package<br />\n\t\ti. The Pandas acronym comes from a combination of panel data and</p>\n\n\t\t<p>Python data analysis. It targets five typical steps in the processing and analysis of data, regardless of the data origin: load, prepare, manipulate, model, and analyze.</p>\n\n\t\t<p>ii. Pandas places much emphasis on flexibility, for example, in handling disparate cell separators. Moreover, it reads directly from the cache or loads Python objects serialized in files by the Python pickle module.</p>\n\t\t</li>\n\t\t<li>\n\t\t<p>Numpy package: manipulating arrays</p>\n\t\t</li>\n\t\t<li>\n\t\t<p>Optparse package&nbsp;</p>\n\t\t</li>\n\t</ol>\n\t</li>\n</ol>\n\n<p>Abstract</p>\n\n<p>I present an evaluation of Apache Spark for streamlining predictive models which use information from CMS data -services. The models are used to predict which datasets will become popular over time. This will help to replicate the datasets that are most heavily accessed, which will improve the efficiency of physics analysis in CMS. The evaluation will cover implementation on Apache Spark framework to evaluate quality of individual models, make ensembles and choose best predictive model(s) for new set of data.</p>\n\n<p>The task in this project is to predict popular datasets. Finding the popular datasets is helpful in a two-fold way. Firstly, it helps in providing expeditious access to datasets that might be required and secondly, it helps in finding which might become the &lsquo;hot topics&rsquo; in high energy physics. It is also necessary to define what a popular dataset is. Based on the data collected, some parameters such as nusers, naccesses and tot_cpu can be said to define popularity because the curve between all the parameters and popularity is mostly dependent on them. To find the numerical value of the threshold limit beyond which a dataset is termed popular, a graph is plotted. This graph is plotted on the log scale so that all values can be plotted within the region represented by the graph.</p>\n\n<p>After calculating the threshold values, transformation into a classification problem is done. Now, a rolling forecast is performed. This helps us to predict binary popularity values for each week. Each week&rsquo;s data is added to the existing data and a new model is created. This follows the notion, more data leads to better data analysis. Prediction can be done in various ways following implementation of several machine learning algorithms, mainly, Naive Bayes, Stochastic Gradient Descent and Random Forest. Their models are then combined into an ensemble to check which algorithm offers the best true positive, true negative, false positive or false negative value.</p>\n\n<p>This project also includes plotting the results obtained against the time scale to get a notion of how accuracy scores change with each week. These include sensitivity, specificity, precision, and recall and fallout rate against time scale.&nbsp;</p>", 
      "title": "Evaluation of Apache Spark as Analytics as framework for CERN's Big Data Analytics", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Ganju, Siddha", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kuznetsov, Valentin", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Wildish, Tony", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Martin Marquez, Manuel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Romero Marin, Antonio", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-CharlesNewey.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>Basic Systems Monitoring</p>\n\n<p>This is now done with a CERN-made custom collector which sends data in the form of &quot;notifications&quot; via Apache Flume to HDFS for long-term storage. The notifications are also sent to ElasticSearch and displayed with Kibana (a\u0300 la Splunk). Due to limitations of the architecture, the system data is collected every 5 minutes which is not ideal.</p>\n\n<p>The idea is to implement a solution which allows more fine-grained sampling of system metrics. Possible ideas are OpenTSDB (to leverage the existing Hadoop infrastructure) or prometheus.io, which should be simpler to setup but it only scales out by sharding. OpenTSDB initially seems like a more promising solution, so investigate the various collection and display alternatives.</p>\n\n<p>Logs Management and Centralisation.</p>\n\n<p>This is now done only for syslog with Apache Flume - shipping to HDFS (and kept &quot;forever&quot;) and to Elasticsearch/Kibana, with a 1 month retention time. There are two issues: flexibility of the collection process, and authorisation.</p>\n\n<p>On the flexibility side, collected messages need to be split into different fields before being stored in HDFS/Elasticsearch, in order to ease the data mining process. Logstash and grok are potentially promising solutions.</p>\n\n<p>On the authorisation side, the idea here is to specifically target the Weblogic installations in order to expose to clients their application logs in a convenient way, and as we host very different applications with different confidentiality levels (amazing what can be found in some application logs!) we need to put an authorisation layer on top of HDFS and ElasticSearch (Kibana just being JS querying ElasticSearch directly). For this there are some methods that could be implemented on HDFS, and for ElasticSearch there is a FOSS plugin to be checked. This part would probably involve setting up an ElasticSearch cluster first.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>There are a number of problems with the current monitoring infrastructure in IT-DB which currently make it difficult to diagnose certain system issues. These include lack of support for certain log formats, latency in messages, and inflexibility of architecture. Several changes to the log monitoring service architecture were evaluated over the period of several weeks, focusing on improving performance, verbosity, and reducing latency. Additionally, several changes to the metric monitoring architecture were evaluated, including deploying a new time-series database to test performance and latency. There were also a number of extra tests conducted on third-party visualisation dashboards and Elasticsearch security software. The proposed log monitoring architecture was found to be useful, and will be the subject of further development and evaluation. The proposed metric monitoring architecture was also found to be useful, but needs further investigation to decide if it is a significant enough improvement over the current architecture to be of value. There were also several software packages found to be unsuitable or unstable, and these are not used in the proposed system architectures. The evaluation was largely successful as much of the work was either found to be unsuitable or will be the subject of further development.&nbsp;</p>", 
      "title": "Streamlining Infrastructure Monitoring and Metrics in IT- DB-IMS", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Newey, Charles Callum", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Tenaglia, Giacomo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Wiecek, Artur", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-JavierDelgadoFernandez.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>The Worldwide LHC Computing Grid (WLCG) includes more than 170 grid and cloud computing centres in 40 countries. More than 2 million computational jobs are being executed on a daily basis and petabytes of data are transferred between sites. Monitoring the job processing activity of the LHC experiments, over such a huge heterogeneous infrastructure, is really demanding in terms of computation, performance and reliability. Furthermore, the generated job monitoring flow is constantly increasing, which represents another challenge for the monitoring systems.</p>\n\n<p>While existing solutions are traditionally based on Oracle for data storage and processing, recent developments in the SDC monitoring team evaluate different NoSQL solutions for processing large-scale monitoring datasets. Among those solutions is ElasticSearch &ndash; an open source distributed real time search and analytics engine. The aim of this project is to prototype the WLCG Job Monitoring applications to store and retrieve data using ElasticSearch.&nbsp;</p>", 
      "title": "Processing of the WLCG job monitoring data using ElasticSearch", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Delgado Fernandez, Javier", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Karavakis, Edward", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Andreeva, Julia", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-SuryaSeetharaman.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification and Motivation</p>\n\n<p>The multi-client benchmark framework of the Huawei Cloud Storage system at CERN was using ROOT5 to provide an analysis about the collection of data retrieved by the clients. Recently a new version of ROOT (ROOT6) was released with many improvements. Hence, to use the benchmark framework more effectively, it had to be upgraded so that it could run using ROOT6. Also this benchmark framework is generic in the sense that this upgraded benchmark framework can be used for measuring the scalability of other storage technologies at CERN like Kinetic Drives or EOS.</p>\n\n<p>As a part of the Data and Storage Services group of the IT department (IT-DSS) at CERN, the task was to upgrade the cloud storage benchmark framework and run the existing tests on the upgraded benchmark.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>The European Organisation for Nuclear Research (CERN) is the largest research center in the world in the field of particle physics. Huge amounts of data, in the order of Peta Bytes, are being generated from the High Energy Physics experiments going on at CERN. The massive data growth prompts CERN to evaluate new storage technologies, to store and analyse the data that is being generated from the experiments. The scalability of the storage system is important for CERN as the laboratory faces the ever increasing demands of its physics users.</p>\n\n<p>Huawei, a CERN collaboration member, focuses on investigating the applicability of new storage techniques and architectures to the storing of high energy physics data from the LHC e\udbff\udc00peri\udbff\udc01e\udbff\udc02ts. I\udbff\udc02 earl\udbff\udc03 \udbff\udc04\udbff\udc05\udbff\udc06\udbff\udc04, Hua\udbff\udc07ei\udbff\udc08s \udbff\udc09loud storage s\udbff\udc03ste\udbff\udc01 \udbff\udc07as deli\udbff\udc0aered to the CERN site, and in three months, the installation and benchmark performance evaluation \udbff\udc07ere \udbff\udc09o\udbff\udc01pleted. Hua\udbff\udc07ei\udbff\udc08s \udbff\udc09loud storage pro\udbff\udc0aed to sho\udbff\udc07 horizontal scalability in writing and reading performance and capability to automatically recover from storage node failures.</p>\n\n<p>One of the main objectives of the Huawei - CERN partnership is to investigate the performance and scalability of a new cloud storage system and compare the results with more traditional approaches used at CERN. To perform this quantitative study, a multi- client benchmark has been developed using ROOT to allow statistical data analysis. Currently, a new version of ROOT has been released with many improvements. In order to allow for more efficient testing and rapid deployment of new benchmark workloads, the existing multi-client benchmark had to be upgraded to be compatible with ROOT 6.</p>\n\n<p>This report documents and justifies that the benchmark framework was upgraded and verified to be able to produce the same results as the previous benchmark framework before the upgrade.&nbsp;</p>", 
      "title": "Upgrading the Huawei Cloud Storage Benchmark Framework for ROOT6 Compatibility", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Seetharaman, Surya", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Arsuaga Rios, Maria", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Heikkila, Seppo S.", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-IvanaPejeva.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>The big amount of data produced by CERN experiments at the Large Hadron Collider (LHC) needs to be efficently stored and analyzed. Because of the constant increasing data volume the essential function at CERN is archiving the vast quantities of data.</p>\n\n<p>The Data and Storage Service Group in the IT department at CERN is operating and evaluating different cloud storage technologies to ensure that all incoming data from experiments can be stored reliably in a cost effective way.</p>\n\n<p>One of the main storage systems used and developed at CERN is EOS [1], a multi- petabyte disk storage. A recent R&amp;D project aims to integrate the Seagate Kinetic drive technology [2] as a promising storage solution for the future. Seagate Kinetic offsers ethernet enabled disk drives with an object storage API.</p>\n\n<p>The main goal of this project is a performance evaluation of Seagate Kinetic drive technology and its integration into the CERN EOS storage system.&nbsp;</p>", 
      "title": "Evaluating the Performance of Seagate Kinetic Drive Technology and its Integration into the CERN EOS Storage System", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Pejeva, Ivana", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Peters, Andreas J.", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-MartiaPriisalu.doc"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution", 
        "url": "http://www.opendefinition.org/licenses/cc-by", 
        "id": "cc-by"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>Crowdsourcing is gaining popularity in academia with the launch of crowdsourcing platforms such as Crowdcrafting [Lombra&ntilde;a, 2015] and GeoTagX [UNOSAT, 2015]. There have been a number of proposed algorithms for the aggregation of true labels and a confusion matrix from crowdsourced labels for ordinal, nominal and binary labels.</p>\n\n<p>The work here consists of an implementation of the Dawid Skene [Dawid 1979] adaptation of the Expectation Maximization algorithm [Dempster 1977] for the extraction of true labels from binary data.</p>\n\n<p>The second part of the project is the planning of the 2015 edition of an open-source promoting coding event for CERN Summer Students called the CERN Webfest.&nbsp;</p>\n\n<p>Abstract</p>\n\n<p>Crowdsourcing is a method in which multiple individuals with possibly no prior knowledge in the field solve a number of tasks. The solutions given by the individuals are then aggregated to infer the true solution from the common knowledge of the individuals.</p>\n\n<p>In this paper we give a short overview of some of the aggregation methods and hybrid crowdsourcing solutions used. We then implement the label aggregation model proposed by Dawid and Skene [Dawid 1979] for open source and open science websites such as Crowdcrafting.org [Lombra&ntilde;a, 2015] and the UNOSAT project GeoTagX [UNOSAT, 2015].</p>\n\n<p>Finally we also discuss the organization and results of the CERN Webfest 2015, a hackathon for CERN Summer Students.</p>", 
      "title": "Aggregating Labels in Crowdsourcing Data", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Priisalu, Maria", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Grey, Francois", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Segal, Ben", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-JimmyAguilarMena.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Project Specification</p>\n\n<p>This project concerns the field of autovectorization and GPGPU programming for the Gaudi framework of LHCb experiment at CERN. This paper summarises the results and progress of some autovectorized, OpenCL or CUDA&reg; implementations for a typical Kalman Filter function that could improve the current or future versions of Gaudi.</p>\n\n<p>Abstract</p>\n\n<p>LHCb is a single arm forward spectrometer at the LHC collider, designed to do precision studies of beauty and charm decays, among others. The first step is the reconstruction of tracks in the vertex detectors with a Kalman Filter. Reducing this means freeing up resources to do a more sophisticated reconstruction in events with a displaced vertex, lending to a more efficient triggers. These challenges will become even more important for the LHCb upgrade.</p>\n\n<p>Gaudi is an architecture and framework for event processing applications in the LHCb experiment at CERN. The Kalman filter routine is an important section in the code that can use around the 10% of the calculation time in some cases. It is extensively used in many other applications. This project is an initial study for some proposed optimizations and modification to improve the performance behaviour of the Kalman filter routine in a Gaudi function using autovectorization and general purpose GPU programming using OpenCL and CUDA&reg;</p>", 
      "title": "Kalman Filter Improves Using GPGPU and Autovectorization for Online LHCb Triggers", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Aguilar Mena, Jimmy", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Campora Perez, Daniel Hugo ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Schiller, Manuel Tobias", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Neufeld, Niko", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-MeganPotter.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Executive Summary</p>\n\n<p>Zenodo, a simple and innovative open science research data repository built by CERN for the world, is rapidly gaining popularity and growing fast.</p>\n\n<p>The aim of&nbsp;this openlab summer student project is to 1) conduct a thorough usability study of Zenodo, to ensure that the simplicity of the service is maintained despite rapid growth, and 2) help implement the outcome of the study as well as to identify and write key guides to increase engagement with end-users. The usability study will focus both the general Information Architecture as well as UX/UI, data model and application profile.</p>\n\n<p>The project is expected to employ a suite of usability evaluations methods such as card sorting, heuristic evaluation and A/B testing.</p>\n\n<p>Abstract</p>\n\n<p>Once a digital repository reaches the stage where Zenodo is, the next step is to review the site to improve usability.&nbsp; This usability overview revealed a strong need for help guides to assist users and additional policies and documentation to be written and/or made openly available in order to meet best practices standards such as ISO 16363.&nbsp; As such, over the course of the 2015 openlab internship, user guides were created in order to improve the user experience and to resolve the problem of insufficient documentation on a variety of topics.&nbsp; Several topics covered were Zenodo specific while others are more general issues important to all digital repositories.&nbsp; In order to achieve compliance with best practices, a review of authoritative documentation was performed.&nbsp; Required policies were outlined in detail and passed along to management for completion.&nbsp; The documentation consulted was Data Seal of Approval, ISO 16363, and the requirements for a particular publisher&rsquo;s data integration program.&nbsp; To certify its successful compliance with best practices, upon the completion of additional documentation, Zenodo will apply for the Data Seal of Approval.</p>", 
      "title": "Zenodo Information Architecture and Usability", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Potter, Megan", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Nielsen, Lars Holm ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-HarunUrhan.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>The project&rsquo;s objective is evaluating Oracle&rsquo;s Big Data Integration Tools. The project covers evaluation of two of Oracle&rsquo;s tools, Oracle Data Integrator: Application Adapters for Hadoop to load data from Oracle Database to Hadoop and Oracle SQL Connectors for HDFS to query data stored on a Hadoop file system by using SQL statements executed on an Oracle Database.</p>", 
      "title": "Evaluation of Oracle Big Data Integration Tools", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Urhan, Harun", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Baranowski, Zbigniew  ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Benjamin_Lipp.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "OpenStack Trove: Evaluation and Interfacing with the CERN Database on Demand Service", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Lipp, Benjamin Ernst", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Coterillo Coz, Ignacio", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>As part of the ongoing migration of CERN&rsquo;s virtual infrastructure to an OpenStack&nbsp;based solution the&nbsp;CERN IT-DB group, responsible of the Database&nbsp;on Demand service, is migrating towards OpenStack&nbsp;from an Oracle&nbsp;VM platform, on an effort to converge with the global CERN&nbsp;IT&nbsp;infrastructure&nbsp;platforms.&nbsp;The Database on Demand Service is a Database as a&nbsp;service developed in-house within the&nbsp;CERN&nbsp;IT&nbsp;DB&nbsp;group.&nbsp;The&nbsp;service&nbsp;manages the underlying infrastructure while providing the end user with an easy to use interface to perform database backups, recoveries, database configuration, and monitoring. Since its most recent release Icehouse, the OpenStack platform includes a new component, named Trove, which provides Database as a Service functionalities. Thus, the main goal of the project is to evaluate this component, OpenStack Trove, from the point of view of the feasibility of using it as a resource provider for the Database on Demand service. With this objective, some major points of interest are: the current status and maturity of the Trove project, ability to support additional database types, and compatibility with Scientific Linux as the computing platform running most CERN services. A secondary goal of the project is to evaluate different Java interfaces to OpenStack which would enable the service&rsquo;s software to interact with the OpenStack service to create and manage instances for the database servers.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Ties_de_Kock.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Batch Share Management Tool", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "de Kock, Ties ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Belleman, J\u00e9r\u00f4me ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Schwickerath, Ulrich  ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project goals</strong></p>\n\n<p>One of the key computing services at <em>CERN </em>is the <em>central batch system</em>. The central batch service currently consists of around 4000 machines with thousands of users, divided over more than 250 groups. The central batch service system runs <em>IBM/Platform LSF</em>r. Additionally, a pilot service based on <em>HTCondor </em>is currently being set up. In a batch system the worker nodes are shared among the users over time. The central batch service uses <em>fair-share </em>scheduling, which ensures that, over a historic time window, a group of users can use the capacity (<em>share</em>) that is assigned to them. Each share on the system is allocated to a group of users. Compute coordinators can delegate capacity, as well as the control of this capacity to subgroups. This situation is shown in figure 1.</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-HamzaZafar.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract&nbsp;</strong></p>\n\n<p>This project deals with two aspects of improving the file transfer service &ndash; FTS3. The first one is the selection of best source site for file transfers. Since files are replicated at different sites, the selection of the best source site based on the networks throughput and success rate can have a major impact on FTS3. The second one is maximizing the file throughput across WLCG network by increasing the TCP buffer sizes. TCP is the only transport layer protocol used widely for data transfers; it was originally designed with focus on reliability and long-term fairness. In high bandwidth networks, the system administrators have to manually optimize/tune the TCP configurations. Some of these configurations have a major impact on throughput. TCP buffer size is one such setting, which sets a limit on TCP congestion window size. With the release of Linux Kernel 2.6, a new feature &ldquo;Linux TCP Auto-Tuning&rdquo; was introduced, which selects the optimal TCP buffer sizes based on system resource usage. Another way to increase the TCP buffer size is to use setsocketopts system call. Since FTS3 implements gridFTP protocol, it gives us the flexibility to set TCP buffer sizes manually. This project evaluates the pros and cons of different techniques for setting TCP buffer sizes.&nbsp;</p>\n\n<p>Keywords: FTS3, TCP , Linux TCP Auto-Tuning&nbsp;</p>", 
      "title": "Improving File Transfer Service \u25ac FTS3", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Zafar, Hamza", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Keeble, Oliver ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Alvarez, Alejandro", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-PawelPamula.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract&nbsp;</strong></p>\n\n<p>The aim of this report is to describe and document the configuration steps and development process of the Openlab Summer Student project. The report explains basic ideas of cloud computing. Furthermore, it introduces Openstack as a software for deploying private clouds. Openstack architecture is further explained. The focus is put on Keystone Identity Service and its architecture and role that it serves in the whole Openstack environment.&nbsp;</p>\n\n<p>Moreover, federation as a mechanism for establishing trusts between identity providers and OpenStack clouds is described. Eventually, further details are provided on token revocation mechanism. The last part describes the means for testing and debugging Openstack deployments.</p>", 
      "title": "Keystone Identity Service in Openstack", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Pamula, Pawel", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Denis, Marek", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-GuidoArnauAntoniucci.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>The EN-STI-EET group is currently working on implementing a Monte Carlo Treatment Planning System (MCTPS) for proton therapy based on FLUKA. Since physics simulations are extremely CPU intensive, a full Monte Carlo based TPS will be almost unaffordable if no any sophisticated optimization is employed.</p>\n\n<p>In this project the Intel Xeon Phi coprocessor will be tested as a tool to speed up the pre-optimization of a Treatment Plan. Firstly, a tool to evaluate the fitness score of a solution will be built and, in the second part of the project, a genetic algorithm and a steepest descent algorithm will be implemented to optimize the treatment.</p>", 
      "title": "FLUKA Pre-Optimizer for a Monte Carlo Treatment Planning System", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Antoniucci, Guido Arnau", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Vlachoudis, Vasilis", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kozlowska, Wioletta", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-MarijaPinkute.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>At CERN Oracle Application Express (APEX) is widely used to facilitate development of web applications based on data stored in Oracle.&nbsp;</p>\n\n<p>The task of the project was to develop a tool for backing up the in case of data loss or corruption. The first part of the project constituted of examining available backup solutions and the ways that APEX stores data. It was concluded that there is no tool that would fulfill all the desired requirements of: exporting everything at once, dealing with two versions of APEX and would include all the attached external files.&nbsp;</p>\n\n<p>A Java tool was developed that included all the missing functionality. Moreover, a simple wrapper was written to provide a way to restore the APEX environment from backups. Tools were successfully tested by automated tests, expert examination of complex applications restored afted backup and on the largest APEX installation at CERN.&nbsp;</p>", 
      "title": "APEX Backup Tool Development", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Pinkute, Marija", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Dziedziniewicz-Wojcik, Katarzyna Maria ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-StavrosMoiras.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>Many teams at CERN, develop their own software to solve their tasks. This</p>\n\n<p>software may be public or it may be used for internal purposes. It is of major</p>\n\n<p>importance for developers to know that their software is secure. Humans are able</p>\n\n<p>to detect bugs and vulnerabilities but it is impossible to discover everything when</p>\n\n<p>they need to read hundreds&rsquo; lines of code. As a result, computer scientists have</p>\n\n<p>developed tools which complete efficiently and within minutes the task of analysing</p>\n\n<p>source code and finding critical bugs and vulnerabilities. These tools are called</p>\n\n<p>static analysis and they are able to find, analyse and suggest solutions to the</p>\n\n<p>programmer in the early stages of development.</p>\n\n<p>The goal of this project is to evaluate and compare as many static analysis tools</p>\n\n<p>as possible (both freeware and commercial) according to metrics decided by</p>\n\n<p>CERN Security Team. The final result should not only be a selection of tools per</p>\n\n<p>language that software developers should utilise but also an automated way to use</p>\n\n<p>them and get useful reports that will help developers write better software.</p>", 
      "title": "Source Code Review Using Static Analysis Tools", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Moiras, Stavros", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Lu\u0308ders, Stefan", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Tsouvelekakis, Aimilios", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "Veronia_Bahaa.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Development of Monitoring and Analysis Tools for the Huawei Cloud Storage System", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Bahaa, Veronia ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Arsuaga-Rios, Maria ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Heikkila, Seppo S. ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>CERN is the largest research centre for particle physics research in the world. Experiments generate large amounts of data which must be stored, processed and analysed. The storage solutions should provide large data capacity, scalability and reliability.&nbsp;</p>\n\n<p>The openlab CERN-Huawei partnership aims at testing and evaluating the performance of the Huawei Universal Distributed Storage system. Benchmarking and monitoring tools are developed to investigate the storage system behaviour.&nbsp;</p>\n\n<p>This report describes the upgrades done for the monitoring and analysis tools used by the Huawei cloud storage system at CERN. The first part of the report describes the additions done to the monitoring system of the cloud storage. The rest of the report describes the improvements done for scripts for listing files on the storage and monitoring their size.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Luca_Tartarini.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Federation of OpenStack clouds", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Tartarini, Luca ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Denis, Marek ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>Rackspace and CERN are implementing federated identity of OpenStack clouds within the&nbsp;OpenStack cloud project. The project is to enhance the client tools in OpenStack to support Thefederated identity functionalities, work with the open source community to incorporate these changes into the product and adapt the documentation and testing. The student will learn about the internals of OpenStack, federated identity techniques such as SAML and working with open source communities.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>The aim of this report is to describe and document the configuration steps of the Openlab Summer Student project. The main goal of the project was to create a testbed for cloud federation for performing federation tests with multiple Identity Providers at the same time and test them with both browser and CLI (Command Line Interface). At the beginning this report gives a general overview of the main concepts on which the project is based, with particular reference to Keystone, the OpenStack Identity Service, describing its main features and how it works. Later are described the protocols and the open source solutions and products (Shibboleth SP, Shibboleth IdP, Shibboleth EDS, ADFS) used for the creation and testing of the testbed. In the following chapters is documented step by step the testbed&#39;s configuration. This is the main part of the report and it gives the details of how to install OpenStack and configure its Identity Service running in HTTPD with Shibboleth Service Provider. Then is described how to federate each Identity Provider with Keystone Identity Service providing the main configuration files. The last part describes the testing in which each Identity Provider has been tested both via CLI (ECP - Enhanced Client or Proxy) and via web browser in order to receive from Keystone a token with which the end user could perform some OpenStack operations.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Sofia_Danko.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "PaaS Solutions Evaluation", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Danko, Sofia ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Tenaglia, Giacomo ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Wiecek, Artur", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>OpenShift Origin is an open source software developed mainly by Red Hat to provide a Multilanguage PaaS. It is meant to allow developers to build and deploy their applications in a uniform way, reducing the configuration and management effort required on the administration side. The aim of the project is to investigate how to deploy OpenShift Origin at CERN, and to which extent it could be integrated with CERN &quot;Middleware on Demand&quot; service. The student will be exposed to modern cloud computing concepts such as PaaS, and will work closely with the IT middleware experts in order to evaluate how to address service needs with a focus on deployment in production. Some of the tools that are going to be heavily used are Puppet and Openstack to integrate with the IT infrastructure.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>The report is a brief summary of Platform as a Service (PaaS) solutions evaluation including investigation the current situation at CERN and Services on Demand provision, homemade solutions, external market analysis and some information about PaaS deployment process. This first part of the report is devoted to the current status of the process of deployment OpenShift Origin at existing infrastructure at CERN, as well as specification of the common issues and restrictions that were found during this process using different machines for test. Furthermore, the following open source software solutions have been proposed for the investigation of possible PaaS provision at CERN:</p>\n\n<ul>\n\t<li>OpenShift Online;</li>\n\t<li>Cloud Foundry;</li>\n\t<li>Deis;</li>\n\t<li>Paasmaster;</li>\n\t<li>Cloudify;</li>\n\t<li>Stackato;</li>\n\t<li>WSO2 Stratos.</li>\n</ul>\n\n<p>CERN &lsquo;homemade&rsquo; solution called Middleware Manager Service was also examined as well as series of proprietary software to compare the features and possibilities of integration. The second part of report contains information about Cloud Foundry PaaS solution and about the process of its deployment at CERN.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Jakub_Zitny.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Oracle TimesTen in-memory Database Integration", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "\u017ditn\u00fd, Jakub ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Potock\u00fd, Miroslav ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>The objective is to build an rpm/script/puppet module that will easily deploy TimesTen in-memory database on existing server/cluster. Create script configuring TimesTen in-memory database for usage with specific database/RAC and creating step-by-step document (Twiki+Snow KB) on how to get required data cached in a simple way. Ultimate outcome will be to have a new service to deploy TT caching easily on any puppetized DB server.</p>\n\n<p><strong>Abstract </strong></p>\n\n<p>TimesTen is in-memory database from Oracle with ability to be attached as a cache to existing Oracle Database. The installation process of TimesTen requires a lot of configuration to be done and although Oracle provides some installation scripts to simplify that, one still needs to take a lot of steps and time to set everything up. This work explores the TimesTen configuration options, proposes the solution for automating as much of the setup as possible and presents the easiest ways to build a working in-memory cache layer for Oracle.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Robert_Winchell.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Presenting News in Invenio", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Winchell, Robert ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kasioumis, Nikos ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>Within the Invenio digital library platform,</p>\n\n<p>1. Migrate the WebNews module, responsible for announcing news, from the current stable version of the software to the latest development version.</p>\n\n<p>2. Introduce a web interface to allow the display and management of news for users and administrators .</p>\n\n<p>3. Investigate alternative JavaScript libraries for news tooltips.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>The first step is discussing the process of learning and integrating the current WebNews code. Then there will be details on the new interface features that were added as well as the new tooltip functionality. There will also be information on the tooltip library and details on future work within this module.</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-ChristinaQuast.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>For the next run of the LHCb experiment, new detectors are built, which use a&nbsp;different&nbsp;protocol from the one used for the old detectors in order to send the data collected&nbsp;from a collision. The data throughput will increase from the currently used 400 Gbit&nbsp;per second to astonishing 40 Tbit. The LHCb upgrade team built two FPGA boards:&nbsp;AMC40 and PCIe40 (see image 1.1). The AMC40 board has an Ethernet interface,&nbsp;produces UDP packets and sends them over the network. The PCIe40 board sends data&nbsp;over PCIe to a server, which in turn creates the network packets based on the PCIe data&nbsp;received, and sends them over the network. Each board is connected to the detectors&nbsp;and contains an FPGA, which does the preprocessing of the data received from the&nbsp;detector. The readout system is connected to the network and sends network packets&nbsp;to the backbone (see image 1.2). The readout system will operate at an overall speed of&nbsp;around 40 Tbit/s. In order to have a means of debugging all this network traffic, tools&nbsp;are necessary. The implementation of such a tool is the task for this Openlab Summer&nbsp;Student project.</p>", 
      "title": "Implementing the Network Debugging Infrastructure for the New Detector Readout Board", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Quast, Christina", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Neufeld, Niko", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Schwemmer, Rainer", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-ZahariKassabov.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>CERN is running several large WinCC OA distributed sys- tems, each of them counting ~100-150 computers and several thousands of processes. The log files currently produced by these processes are only looked at very seldom to debug prob- lems. The project will consist of introducing a modern log analysis tool to analyze these log files in real time and inform the operators/experts of possible problems. The tools will also be used to extract statistics and produce reports about the control systems. The selected tool will be Elastic Search with Kibana.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>This project has consisted in examining different alternatives for monitoring and ana- lyzing the log messages produced by the control system software using at CERN. Its main accomplishments have been a performance measurement of the Logstash tool un- der both realistic and extreme load scenarios, the development of a flexible and powerful performance testing tool, and the proposal of a system that automatically determines the importance that a given log message might have for an operator based on a Bayesian filter.&nbsp;&nbsp;</p>", 
      "title": "Log Analysis and Classification of CERN Control Systems", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Kassabov, Zahari", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Gonzalez Berges, Manuel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-IrinaGrigorescu.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>In most distributed systems dedicated to scientic projects, a very important part of delivering qualitative services is the monitoring layer that runs on top of such infrastructures.&nbsp;The scope of our project was to ensure a successful backbone for the data processing, by&nbsp;providing meaningful dashboards which will help understand, debug and improve CERN&#39;s&nbsp;large batch computing service. Therefore, our project was dedicated to developing an infrastructure meant to collect and display monitoring information about the system by the&nbsp;means of Lemon Sensors and Kibana data visualization platform.</p>", 
      "title": "Batch Monitoring Dashboards", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Grigorescu, Irina", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Belleman, Jerome", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentreport-AncaPopescu.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract&nbsp;</strong></p>\n\n<p>The ROOT system provides a set of OO frameworks with all the functionality needed to handle and analyze large amounts of data in a very efficient way. Having the data defined as a set of objects, specialized storage methods are used to get direct access to the separate attributes of the selected objects, without having to touch the bulk of the data. Included are histograming methods in an arbitrary number of dimensions, curve fitting, function evaluation, minimization, graphics and visualization classes to allow the easy setup of an analysis system that can query and process the data interactively or in batch mode, as well as a general parallel processing framework, PROOF, that can considerably speed up an analysis.&nbsp;</p>\n\n<p>In addition, ROOT offers an ensemble of advanced mathematical functions such as Bessel and Airy functions or distributions such as Landau, gammma, Cauchy or Breit-Wigner. These functions are relevant for a variety of performance critical applications, among which the statistical studies in HEP such as discoveries and exclusions. This kind of activities will be more and more important during the forthcoming 13 TeV collisions at the LHC.&nbsp;</p>", 
      "title": "Vectorisation and GPUs Extensions of ROOT::Math Routines", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Popescu, Anca", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Moneta, Lorenzo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Piparo, Danilo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Joao_Goncalves.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>The aim of this openlab summer student project is to enhance ZENODO digital repository service with several preservation-oriented features, such as preservation meter and badge to indicate the&nbsp;suitability of a document for long-term reservation. The project will be developed in the Python&nbsp;programming language, using Flask/HTML5/jQuery/TwitterBootstrap technologies for the user&nbsp;interface and SQLAlchemy/MySQL for persistence.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>Digital Preservation consists mainly in storing digital information, mostly digital-born content,&nbsp;and making sure that it remains available and accessible in the future. This tasks has many&nbsp;challenges such as making sure that the files are in a known and acessible format, that they are&nbsp;not corrupt, lost or unretrievable.&nbsp;The digital preservation challenges apply, noticeably, on digital repositories such as Zenodo.&nbsp;Zenodo aims to provide a secure and trusty way of storing data for the long tail of science. This is&nbsp;to say, storing and connecting information that is normaly not available on the main publications,&nbsp;such as the used datasets for a given study or the produced software for a specfic paper.&nbsp;The goal of this work was to develop a Preservation Meter that allowed the users to know how&nbsp;suitable the files on their submited records are in terms of preservation.This was accomplished by using a simple and intuitive visual representation of such suitability by&nbsp;means of a progress bar, where a completly filled bar means the file is very likely to be well&nbsp;preserved.&nbsp;The overall goals of the project were completed and the implementation of this work was&nbsp;integrated on the Zenodo repository as a plugin.</p>", 
      "title": "Zenodo: Preservation Meter", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Gon\u00e7alves, Jo\u00e3o ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Holm Nielsen, Lars ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Bogdan_Kulynych.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Implementing Memento RFC 7089 for Invenio Digital Library Software", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Kulynych, Bogdan", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Simko, Tibor ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>Implement support of Memento (RFC 7089 [1]), an HTTP framework&nbsp;permitting&nbsp;users to &lsquo;browsethe web in the past&rsquo; via a browser extension,&nbsp;for Invenio&nbsp;digital library software. Implement an&nbsp;HTTP API that exposes&nbsp;historical versions of the research objects managed by Invenio.</p>"
    }
  }, 
  {
    "files": [
      "CERN_Science_and_Technology.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>A high-level&nbsp;overview of the relationship between science and technology at CERN and the impact of technology on research with a focus on ICT technologies. Presented as a 12-minute &quot;power-talk&quot; at CIOCity 2015, Brussels</p>", 
      "title": "CERN Science and Technology", 
      "communities": [], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN openlab", 
        "Technology", 
        "LHC"
      ], 
      "publication_date": "2015-06-04", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-JorgeVicenteCantero.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>A notication system is required by Invenio to fulll the current needs and adapt to the&nbsp;future use cases. Such a system has to be real-time and compatible with its&nbsp;technology&nbsp;stack, notifying the Invenio users almost instantly.&nbsp;In the following sections, the design of this system is described, discussing both the previous&nbsp;requirements and the achieved results. Also, more insight about the used&nbsp;key technologies is given, justifying why they were necessary for the project.&nbsp;The details for building&nbsp;such a system with Python are explained from a&nbsp;theoretical point of view and the necessary concepts for using it are introduced.&nbsp;Lastly, the future of the project is discussed, giving a general overview of&nbsp;it and room for&nbsp;improvements.</p>", 
      "title": "Building a Real-time Notification System", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Cantero, Jorge Vicente", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kuncar, Jiri", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-ShubhamGupta.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>&nbsp;&nbsp;Abstract</p>\n\n<p>WinCC OA is a SCADA (Supervisory Control and Data Acquisition) system tool that is used to develop the Control System applications. As most of the control systems used in CERN are developed in WinCC OA, it is better useful to understand how the applications developed by EN/ICE are actually used by the different operators .It becomes more and more important to monitor users&rsquo; behavior and analyzing it. The final goal of this project is to develop a generic WinCC OA component to collect data about user interaction which will take advantage of (1) the internal mechanisms already present in WinCC OA to monitor some user interactions such as the internal UI data points; and (2) the commonalities of applications through the use of the standard frameworks JCOP, UNICOS and CPC. The final component developed provides the capability of storing as well as displaying user interaction data on a single timeline.</p>\n\n<p>Kewords: WinCC OA, SCADA, JCOP, UNICOS, CPC</p>", 
      "title": "Non-Intrusive User Interaction Monitoring for WinCC OA based Applications", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Gupta, Shubham", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Tournier, Jean-Charles ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-PaolinaDoncheva.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>The CERN Data Centre is the heart of CERN&rsquo;s entire scientific, administrative, and computing infrastructure. All IT services use equipment located in the data centre. Because of its significant role, the performance of the devices deployed in the network is essential for providing high quality network services.</p>\n\n<p>In order to provide a reliable and high-performance network the performance and limitations of each device have to be checked.&nbsp; The Flow Visualizer project consists in developing a flow visualization framework, which enables real-time monitoring of the flows generated by a distributed traffic generator and allows visualizing the monitored information at different levels of detail.</p>", 
      "title": "Flow Visualizer", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Doncheva, Paolina", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Stancu, Stefan", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Krajewski, Adam", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Martelli, Edoardo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Stephen_Wang.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>The project concerns various C++11 features - their performance and reliability. The report summarizes the tesults from four micro-benchmarks designed for this project and run with three different compilers (GCC, ICC, Clang) and tries to make an evaluation based on the results.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>As C++11 gained almost full support by compilers, it is interesting to see whether we can leverage some of the features to improve performance and reliability of C++ code. This work is focused on four selected problems: time measurement techniques, for-loops efficiency, asychronuous tasks and parallel mode of STL algorithms. For each of them a micro-benchmark is made. All the benchmarks are fully automatized to generate results from running binaries compiled by three compilers: GCC, ICC and Clang with -O2, -O3 and -Ofast options. In order to evaluate vectorization and multithreading, profiling tools such as perf and Intel Vtune are used.</p>", 
      "title": "Evaluation of selected C++11 features with GCC, ICC and Clang", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Wang, Stephen ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Szostek, Pawel ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "ISUM_2014_openlab_v1_0.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "CERN openlab: a Model for Research, Innovation and Collaboration", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN openlab", 
        "Computing", 
        "WLCG", 
        "High Energy Physics"
      ], 
      "publication_date": "2014-03-18", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p>This presentation describes the major present and future computing and data challenges in the scientific research done at CERN in High Energy Physics and how the CERN openlab helps in addressing these challenges through collaboration with major industrial companies. This presentation was given at the International Supercomputing in Mexico 2014 (ISUM 2014) conference.</p>"
    }
  }, 
  {
    "files": [
      "BIg_Data_in_Healthcare_Pesaro_20151020.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>The growing availability of large quantities of data from medical devices, laboratory notes, digital simulations, doctors&#39; notes, images, and even social networks are opening new opportunities for medical research and clinical practice. A proper understanding of data, tools and platforms and of how they related to the objective of the research are a necessary first step. The availability of platforms with clear separation of roles, ownership and responsibilities plays a fundamental role in enabling efficient use of data at large scales. What is the state of the art and the possible applications? What can be learned from existing activities in high energy physics?</p>", 
      "title": "Big and Smart Data Analytics - Possible Advantages to Clinical Practice", 
      "notes": "Talk given at the Medical Record Update Workshop organized by the AdriHealthMob project in Pesaro on October 20th-21st", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "presentation", 
      "keywords": [
        "Big data", 
        "Cloud computing", 
        "Medical research", 
        "Clinical practice"
      ], 
      "publication_date": "2015-10-20", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Manca, Marco", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Kacper_Sokol_Blazej.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Making sense of data streams: Complex Event Processing for Controls Applications", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Sokol, Kacper B. ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Tilaro, Filippo ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Voitier, Axel ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>CERN is currently investigating the usage of data&nbsp;analysis&nbsp;technologies&nbsp;to&nbsp;study&nbsp;the behaviour of the&nbsp;industrial control&nbsp;systems. An activity&nbsp;related to these analysis is using Complex Event&nbsp;Processing&nbsp;(CEP) tools to classify a real abnormal behaviour from one&nbsp;generated by a human intervention on&nbsp;the system.&nbsp;In this study the Complex&nbsp;Event Processing classification is run over signals produced by variety&nbsp;of sensors and simulators. The selected tools is Esper. Presented&nbsp;here&nbsp;work consists of installing&nbsp;chosen tool, and developing the&nbsp;classification system with it to address given above merit.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>This project aims at building a tool to process live streams of data produced by&nbsp;various sensors and&nbsp;artificial generators. To this end, a Java code is written,&nbsp;which uses Esper Complex Event Processing&nbsp;package to: receive data&nbsp;feeds, apply user defined rules and filters, and pass the resulting&nbsp;information&nbsp;to a clustering framework.&nbsp;The last step employs Affinity&nbsp;Propagation based clustering algorithm, which choice is motivated&nbsp;by its&nbsp;dynamic adaptation to number of clusters in the data. This is key feature in&nbsp;data streaming&nbsp;scenario as the number of clusters can evolve with time.&nbsp;Furthermore, [Zhang et al., 2013] have&nbsp;documented overall good&nbsp;performance of Affinity Propagation in cases of live data analysis.&nbsp;Finally,&nbsp;presented here approach is compared and contrasted against&nbsp;static clustering algorithms applied&nbsp;to data gathered from streams&nbsp;incoming over one run of the program, followed by in-depth&nbsp;results analysis.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Lindqvist.pdf"
    ], 
    "metadata": {
      "description": "<p>Storage space is one of the most important ingredients that the European Organization for Nuclear Research (CERN) needs for its experiments and operation. Part of the Data &amp; Storage Services (IT-DSS) group&rsquo;s work at CERN is focused on testing and evaluating the cloud storage system that is provided by the openlab partner Huawei, Huawei Universal Disk Storage System (UDS). As a whole, the system consists of both software and hardware.<br />\nThe objective of the Huawei-CERN partnership is to investigate the performance of the cloud storage system. Among the interesting questions are the system&rsquo;s scalability, reliability and ability to store and retrieve files. During the tests, possible bugs and malfunctions can be discovered and corrected. Different versions of the storage software that runs inside the storage system can also be compared to each other.<br />\nThe nature of testing and benchmarking a storage system gives rise to several small tasks that can be done during a short summer internship. In order to test the storage system a test framework developed by the DSS group is used. The framework consists of various types of file transfer tests, client and server monitoring programs and log file analysis programs. Part of the work done was additions to the existing framework and part was developing new tools. Metrics collection was the central theme. Metrics are to be understood as system statistics, such as memory consumption or processor usage.<br />\nMemory usage and disk reads/writes were added to the existing client real-time monitoring framework. CPU and memory usage, network traffic (bytes received/sent) and the number of processes running are collected from a client computer before and after a daily test. Two other additions are visualization for storage system log files, as well as a new monitoring tool for the storage system. This report is divided into parts describing each part of the framework that was improved or added, the problem and the final solution. A short description of the code and the architecture are also included.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Improved metrics collection and correlation for the CERN cloud storage test framework", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Lindqvist, Carolina", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Zotes, Maitane", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Heikkila, Seppo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Anti_Asko.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Investigation on Oracle GoldenGate Veridata for Data Consistency in WLCG Distributed Database Environment", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Asko, Anti ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Lobato Pardavila, Lorena ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>In the distributed database environment, the data divergence can be an important&nbsp;problem: if it is not discovered and correctly identified, incorrect data&nbsp;can lead to poor decision making, errors in the service and in the operative&nbsp;errors. Oracle GoldenGate Veridata is a product to compare two sets of&nbsp;data and identify and report on data that is out of synchronization.&nbsp;IT DB is providing a replication service between databases at CERN and other computer&nbsp;centers worldwide as a part of the WLCG project. One of the important&nbsp;and difficult tasks in provisioning of a reliable replication service is to&nbsp;measure and ensure consistency of data between databases. Oracle Veridata&nbsp;appears to be a promising solution for this challenge. The aim of the&nbsp;project is to evaluate the Oracle Veridata framework in the context of the&nbsp;WLCG database replication environment, to provide a study and feedback&nbsp;regarding functionality, usability and performance of the software for&nbsp;data consistency measuring between remote databases.</p>"
    }
  }, 
  {
    "files": [
      "BBiCat-v1.0.4-alpha.zip"
    ], 
    "metadata": {
      "embargo_date": "2020-08-03", 
      "license": {
        "title": "GNU General Public License version 3.0 (GPLv3)", 
        "url": "http://www.opensource.org/licenses/gpl-3.0.html", 
        "id": "gpl-3.0"
      }, 
      "title": "BBiCat: Alpha version of a Java implementation of BBiCAT project with added License", 
      "description": "<p>This is the Java implementation of a research project on modelling and analysis of complex systems. Release contains Local implementation of the BiMax algorithm, refactored code of BiCat toolbox, Bayesian post-analysis which uses NCI Curated Pathways database, possibilities of calling R script from Java code, Parser that maps illumina names to HGNC Symbols and usage cases of all the above mentioned. Also, a class that can read and process bigger datasets with which BiCat GUI had a trouble. Also, Mean Squared Residue Score implementation is included in the bicluster class to have a numeric metric for assessment as well.</p>", 
      "upload_type": "software", 
      "communities": [], 
      "publication_date": "2015-11-03", 
      "creators": [
        {
          "name": "Taghi Aliyev", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Marco Manca", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Alberto Di Meglio", 
          "affiliation": "CERN OpenLab", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "embargoed", 
      "related_identifiers": [
        {
          "scheme": "url", 
          "relation": "isSupplementTo", 
          "identifier": "https://github.com/TaghiAliyev/BBiCat/tree/v1.0.4-alpha"
        }
      ]
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Montes_Lopez.pdf"
    ], 
    "metadata": {
      "embargo_date": "2020-08-03", 
      "description": "<p><strong>Project Specification:</strong><br />\nThe IT-PES-PS service managers gather a lot of statistics for the services they run. These statistics are currently displayed by SLS (Service Level Status) or Lemon pages. They also use the Web interface provided with OpenTSDB, a DB optimised for time series. And while these various pages give very useful and technical information, they do not always emphasise the important figures. Having different statistics pages makes it difficult to see the relevant numbers at once. The goal of this project was to build homogeneous dashboards with interactive plots to better reflect the activity and resources of each service, showing relevant figures at first sight in a single website.</p>\n\n<p><strong>Abstract:</strong><br />\nThere is a need in the IT-PES-PS section to improve the current situation of having to consult the relevant information from several heterogeneous websites by introducing interactive homogeneous dashboards, accessible from a single web application where the information needed can be quickly accessed. The goal of this openlab Summer Student project was to create a website with homogeneous and interactive dashboards. Its architecture had to allow the creation of new dashboards easily.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Improvement of the IT-PES-PS Section Services Statistics Page", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Montes L\u00f3pez, Alberto", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Belleman, J\u00e9r\u00f4me", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "embargoed"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Peon.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nThe aim of this openlab summer student project is to provide intuitive and powerful visualisation tools for key institutional data about CERN, including budgets and contracts. The project will be done in collaboration with the Open Knowledge Foundation under the framework of CERN&#39;s open data policy regarding scientific results from LHC. The student will use the model-view-controller web development framework with Flask/HTML5/jQuery/TwitterBootstrap technologies for the user interface and SQLAlchemy ORM for database persistence.</p>\n\n<p><strong>Abstract:</strong><br />\nCERN&rsquo;s Open Access Policy says that &ldquo;all results of its experimental and theoretical work shall be published or otherwise made generally available&rdquo;. Following that, CERN has reached a collaboration agreement with the Open Knowledge Foundation in order for CERN to publish and visualize institutional data. As part of this collaboration, we will develop a module for showing this data in a graphical way in the CERN side and a tool in the Open Knowledge Foundation site for automatizing the input of data.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Advanced Visualizations Tools for CERN Institutional Data", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Rodr\u00edguez Pe\u00f3n, Alberto", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kun\u010dar, Ji\u0159\u00ed", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Almalioglu.pdf"
    ], 
    "metadata": {
      "description": "<p>Many physics and performance studies carried out with the ATLAS detector at the Long Hadron Collider (LHC) require very large event samples. A detailed simulation for the detector, however, requires a great amount of CPU resources. In addition to detailed simulation, fast techniques and new setups are developed and extensively used to supply large event samples. In addition to the development of new techniques and setups, it is still possible to find some performance improvements in the existing simulation technologies.<br />\nThis work shows some possible ways to increase the performance for different full and fast ATLAS detector simulation setups, using new libraries and code improvements in the ATLAS detector simulation framework. Besides of the improvements, measured time consumptions of different setups are shown and possible further improvements are the other main focuses of this project.</p>", 
      "license": {
        "title": "Creative Commons Attribution", 
        "url": "http://www.opendefinition.org/licenses/cc-by", 
        "id": "cc-by"
      }, 
      "title": "Performance Improvements for the ATLAS Detector Simulation Framework", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Almalioglu Yasin", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Salzburger Andreas", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Ritsch Elmar", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "dummy_file.pdf"
    ], 
    "metadata": {
      "description": "<p>The new release of Oracle 12c contains new features which satisfy continuously growing needs demands for resources. Large enterprises nowadays may use hundreds or thousands of databases combined with different platforms on multiple physical servers. Because of improvements in hardware technology, especially the increase in the number of CPUs, servers are able to handle heavier workloads than before. A database may use only a fraction of the server hardware capacity, which can waste hardware resources.&nbsp;</p>\n\n<p>To show the problem in reduced scale, Figure 1depicts 11 databases, each with its own application and server. A head DBA oversees a team of four DBAs, each of whom is responsible for two or three databases.</p>\n\n<p>One possible solution to the problem is to consolidate data from multiple databases into one database on one computer which is known as database consolidation. Database consolidation is feasible by using new features proposed by Database 12c Release, i.e. Multi-tenant Environment and Pluggable Databases. Multi-tenant environment of Oracle, also, offers a path-breaking technology that delivers &ldquo;Database as a service&rdquo;. Database as a Service (DBaaS) is a paradigm where end users (DBAs, Developers, QA Engineers, Project Leads, etc.) can request database services, consume it for the lifetime of the project, and then have then automatically de-provisioned and returned to the resource pool.</p>\n\n<p>The final goal of this project is to investigate and test the aforementioned features in practise. In the following chapters, we implemented a few test cases related to Pluggable Databases both in Oracle Enterprise Manager12c (EM12c) and SQL Plus environments. These use cases include topics related to users, manipulation of databases and database locations.&nbsp; It is studied the paradigm to make a request for a &ldquo;Database as a Service- DBaas&rdquo; and the necessary steps are described combined with the possible alerts or problems faced and resolved.&nbsp; In chapter 3.5, we have a presentation about the integration of Oracle VM Manager and Oracle Enterprise Manager 12c and a comparison is made between these two tools During this project, some scripts were developed to ease managing of both databases and related users. These support scripts are described in chapter 4.&nbsp;</p>", 
      "title": "DBaaS with Enterprise Manager", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Panagidi, Kyriaki", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Dumitru, Andrei", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Coterillo Coz, Ignacio", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "closed"
    }
  }, 
  {
    "files": [
      "Big_Data_HPC_CERN.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Overview presentation of the CERN and LHC Experiments computing and data infrastructure and the technology evolution strategies being currently evaluated. Presented at the HPC &amp; Big Data Conference, London on 4 Feb 2016</p>", 
      "title": "Big Data for Big Discoveries: How LHC Finds Needles by Burning Haystacks", 
      "communities": [], 
      "upload_type": "presentation", 
      "keywords": [
        "Big Data", 
        "CERN", 
        "CERN openlab"
      ], 
      "publication_date": "2016-02-04", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "Archit_Sharma_OpenLab_Report.pdf"
    ], 
    "metadata": {
      "description": "<p>Invenio is an open source web-based application that implements a digital library or document server, and it&#39;s used at CERN as the base of the CERN Document Server Institutional Repository and the Inspire High Energy Physics Subject Repository.<br />\nThe purpose of this project was to add a new feature to CDS, through which users could manage their own favorite collections on top of existing ones. My work involved adding new features to the WebSearch module, so as to achieve the stated objectives.<br />\nLater on, another task was to parse user searched queries so as to provide end-users with a visualized pattern of search, involving global searched terms or terms popular for a particular collection.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Development of favorite collections & visualizing user search queries in CERN Document Server (CDS)", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Sharma, Archit", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kasioumis, Nikolaos", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Azzara.pdf"
    ], 
    "metadata": {
      "description": "<p>The project aims at evaluating the use of CERN computing infrastructure for next generation sensor networks data analysis. The proposed system allows the simulation of a large-scale sensor array for traffic analysis, streaming data to CERN storage systems in an efficient way. The data are made available for offline and quasi-online analysis, enabling both long term planning and fast reaction on the environment.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "CERN Storage Systems for Large-Scale Wireless", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Azzar\u00e0, Andrea", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Espinal, Xavier", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Lamanna, Massimo", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Doneva.pdf"
    ], 
    "metadata": {
      "description": "<p>This project focuses on testing and developing algorithms for multivariate data analysis, that separate signal processes from abundant backgrounds and on helping with organizing and filtering colossal amounts of raw data, gathered from the Large Hadron Collider beauty (LHCb) experiment, to find extremely rare events of interest. Moreover, working on this project also meant trying to apply new, faster method to take the place of systems that are now used at CERN to pare down the relevant data, but require relatively extensive processing and analysis to determine relevance and usefulness.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Using a new multivariate technique in high energy physics", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Doneva, Viktoria", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Moritz Karbach, Till", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Dul.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification</strong>:<br />\nThe goal of my project was to develop a tool for facilitating controlling internal Oracle database maintenance jobs. Optionally I was proposed to extend the tool with additional components for controlling of other database related settings. The tool had to be easily customizable, work in multi-database environment and provide concise report for further review to in order to facilitate database administration.<br />\n<strong>Abstract</strong>:<br />\nDocument describes DBCheck &ndash; reporting tool for multi-database environment. In particular document describes architecture of a tool, detailed description of verifications made, customization and reports provided. Last part of a document contains short manual about tool usage and reference to further documentation.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Oracle AutoTask enhancement for multi-database environment", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Dul, Tadeusz", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "B\u0142aszczyk, Marcin", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Endre_Andras_Simon.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nOracle TimesTen In-Memory Database is a full-featured, memory-optimized, relational database with persistence and recoverability. For existing application data residing on the Oracle Database, TimesTen can serve as an in-memory cache database. This setup can provide great performance increase and almost instant responsiveness for database intensive applications. Cooperation between application and database support is needed to test integration, benefits and possibilities this product provides for database intensive applications in CERN.<br />\nMain goal is to test performance improvement in response time when using Oracle TimesTen in-memory database cache (IMDB) layer between high load CERN applications and their respective databases.</p>\n\n<p><strong>Abstract:</strong><br />\nIn this paper I will introduce the key features of Oracle TimesTen In-memory database, focusing on the scenario when TimesTen is used as a cache between applications and their databases. Several industry standard benchmarks will be run against both Oracle database and Oracle TimesTen In-memory cache, to determine the performance gains when using Oracle TimesTen as a cache. Based on these results, we will examine the causes and consequences to make future assumptions. After reading this document, the reader will have a broad overview of uses-cases, when using TimesTen is advantageous.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Evaluation of in-memory database TimesTen", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Andras Simon, Endre", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Potocky, Miroslav", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Kolobara.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nThis project should build on the existing participant registration module of Indico and provide additional functionalities for managing the check-in process. While in small conferences it is easy to keep track of participants with a simple paper list, such techniques become inefficient when the need to scale the process up arises. Therefore Indico&rsquo;s participant registration module would be extended with the functionality to generate electronic tickets. This will allow conference organizers to keep track of attendees after they finish the registration process. As part of this project it is also necessary to develop a mobile application that will be used to scan the electronic tickets, identify the user and mark them as checked in when they arrive at the conference. Additionally Indico&rsquo;s HTTP API would be extended to be used by the mobile application to retrieve data about conferences and attendees.</p>\n\n<p><strong>Abstract:</strong><br />\nThe main goal of this project is to simplify the check-in process for conferences that use the Indico conference management system. This is archived by extending Indico&rsquo;s core to include electronic ticket generation functionality and developing a mobile application that is used to scan the electronic tickets during the check-in process. Indico&rsquo;s HTTP API is also extended to provide the mobile application with the necessary data.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Electronic Ticket and Check-in System for Indico Conferences", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Kolobara, Bernard", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Gonzalez Lopez, Jose Benito", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Report_Kraljevic.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification</strong>:<br />\nConnect Invenio digital library with popular cloud storage services such as Google Drive, Dropbox and Sky Drive.</p>\n\n<p><strong>Abstract:</strong><br />\nCloudutils is a standalone python module which provides an interface to popular cloud storage services (e.g. Google Drive, Skydrive&hellip;). It is built on top of the PyFilesystem module. In this project Cloudutils module was developed and used to connect Invenio digital library and popular cloud storage services.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Integration of cloud services with Invenio digital library", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Kraljevi\u0107, \u017deljko", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kun\u010dar, Ji\u0159\u00ed", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-AzqaNadeem.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract&nbsp;</strong></p>\n\n<p>Secure Quick Reliable Login (SQRL) and Universal 2nd Factor (U2F) are two new strong authentication protocols. They both operate on a challenge-response model and use Asymmetric key encryption.&nbsp;</p>\n\n<p>SQRL aims to replace user names and passwords because they are our identity and we cannot trust the websites to keep our personal information safe. In order to authenticate against a SQRL aware service, one has to use the SQRL application on his phone. A perk of using SQRL is that the users only need to remember a master password for the SQRL application itself rather than passwords to all the different authentication services they use.&nbsp;</p>\n\n<p>U2F, on the other hand, is hosted by the FIDO alliance. It has been adapted by big companies, such as Google, Visa, Yubico, etc. It requires a physical U2F enabled token on the client side and a U2F aware authentication service on the server side.&nbsp;</p>\n\n<p>After an evaluation of the two protocols, we have come to a conclusion that at this point, U2F is a better option than SQRL. Hence, a web application has been implemented and deployed on CERN web servers to demonstrate the functionality of U2F.</p>", 
      "title": "Evaluation and Implementation of SQRL and U2F as 2nd Factor Authenticators for CERN Single Sign-On", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Nadeem, Azqa", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Brillault, Vincent", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Lueders, Stefan", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Mcgilvary.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nCERN is establishing a large scale private cloud based on OpenStack as part of the<br />\nexpansion of the computing infrastructure for the Large Hardon Collider (LHC).<br />\nDepending on the application running on the cloud, some virtual machines require large<br />\ndisk capacities or high reliability/performance volumes. This project involves the<br />\nconfiguration, deployment and testing of OpenStack Cinder as well as the integration<br />\nwith other block storage alternatives such as NetApp and Ceph. A performance analysis and comparison between these storage mechanisms will be<br />\nundertaken to determine the most suitable for use at CERN. Furthermore, modifications will also be made to OpenStack to allow user-specified Ceph data striping values to be set during volume creation as well as the Ceph/QEMU caching method upon volume attachment to an instance.</p>\n\n<p><strong>Abstract:</strong><br />\nWith the ever increasing amount of data produced from Large Hadron Collider (LHC)<br />\nexperiments, new ways are sought to help analyze and store this data as well as help<br />\nresearchers perform their own experiments. To help offer solutions to such problems,<br />\nCERN has employed the use of cloud computing and in particular OpenStack; an open source and scalable platform for building public and private clouds.<br />\nThe OpenStack project contains many components such as Cinder used to create block storage that can be attached to virtual machines and in turn help increase performance.However instead of creating volumes locally with OpenStack, others remote storage clusters exist offering block based storage with features not present in the current OpenStack implementation; two popular solutions are NetApp and Ceph.<br />\nTwo features Ceph offers is the ability to stripe data stored within volumes over the<br />\ndistributed cluster as well as locally cache this data, both with the aim of improving<br />\nperformance. When in use with OpenStack, Ceph performs default data striping where<br />\nthe number and size of stripes is fixed and cannot be changed dependent on the volume to be created. Similarly, Ceph does not perform data caching when integrated with OpenStack.<br />\nIn this project we outline and document the integration of NetApp and Ceph with<br />\nOpenStack as well as benchmark the performance of the NetApp and Ceph clusters<br />\nalready present at CERN. To allow Ceph data striping, we modify OpenStack to take the number and size of stripes input via the user to create volumes whose data is then striped according to the values they specify. Similarly, we also modify OpenStack to enable Ceph caching and allow users to select the caching policy they require per-volume. In this report, we describe how these features are implemented.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "The Implementation of OpenStack Cinder and Integration with NetApp and Ceph", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "McGilvary, Gary", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Oulevey, Thomas", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Michelino.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nCERN is establishing a large scale private cloud based on OpenStack as part of the expansion of the computing infrastructure for the LHC. Many cloud based services use auto-scaling and orchestration to expand and contract their resources according to user load. The OpenStack Heat project provides an open source framework to organize the configuration and deployment of cloud applications. After the implementation of a working environment, was tested a sample use case, developing a template that deploys webservers within an auto scaling group behind a Load Balancer and serving webpages hosted on a NFS server. Webservers scale up and scale down according to current load.</p>\n\n<p><strong>Abstract:</strong><br />\nThe aim of this document is to describe the project that was implemented during the openlab Summer Programme &lsquo;Implementation and testing of OpenStack Heat&rsquo;. This document gives a quick brief of what &ldquo;Cloud Computing&rdquo; is and which are the technologies and models used to build a Cloud Computing infrastructure; then it gives an overview on OpenSatck project. The main part of this document gives details on how Heat works and how it has been integrated in the OpenStack project, and gives a reference on how to install and use it. The last part describes a use case that has been deployed to test Heat features, giving some details about the template that implement it.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Implementation and testing of OpenStack Heat", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Michelino, Davide", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Castro Leon, Jose", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Fernandez Alvarez, Luis", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Dimitrios_Sarigiannis.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "SkyGrid Prototype - Cloud-friendly Grid Platform", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Sarigiannis, Dimitrios ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Ustyuzhanin, Andrey ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>Grid architecture is well-known for dealing with distributed computation for many&nbsp;years. Recently other&nbsp;computational models have started to emerge. For&nbsp;example, Hadoop that is based on map-reduce paradigm.&nbsp;The goal of this&nbsp;project would be specification of test cases and development of staging&nbsp;environment that&nbsp;is capable of dealing with those cases in order to&nbsp;provide comparison result between old and new models.&nbsp;Ultimately it would be&nbsp;helpful to identify weak points of both approaches as well as to figure out&nbsp;points&nbsp;of growth for both worlds.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Noe_Fernandez_Alvarez.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Web Application Component Mapping", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Fern\u00e1ndez \u00c1lvarez, No\u00e9 ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Marescaux, Nicolas Bernard ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Wiecek, Artur ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Introduction </strong>&nbsp;&nbsp;</p>\n\n<p>In this project we want to improve the way that the users checks the information concerning to the systems of <strong>IT/DB </strong>infrastructure. Giving easy-to-read representations of the environment in an optimum time.</p>\n\n<p><strong>Project overview </strong></p>\n\n<p>When you are working with dozens of servers and several types of configurations, it&acute;s really important to know all the information concerning to every server in order to make changes, fix problems, etc.</p>\n\n<p>If the environment where you are working is very big, it&acute;s a waste of time to search for all this information because the data repositories doesn&acute;t has a human-friendly format and it&acute;s really difficult to understand and read. Furthermore, if new people is starting to work in our environment, it&acute;s quite difficult for them to understand the structure of the environment and how to read this information.</p>\n\n<p>So we need a tool to process all this information, to make a standard and easy-to-read representation of the environment but giving the same details than the stored information, saving time and increasing the comprehension of the system.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Vintila.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nThe goal of this Openlab Summer Student project was to assess the implications and the benefits of integrating two standard IT tools, namely Icinga and Splunkstorm with the existing production setup for monitoring and management of control systems at CERN.<br />\nIcinga &ndash; an open source monitoring software based on Nagios would need to be integrated with an in-house developed WinCC OA application called MOON, that is currently used for monitoring and managing all the components that make up the control systems.<br />\nSplunkstorm &ndash; a data analysis and log management online application would be used stand alone, so it didn&rsquo;t need integration with other software, only understanding of features and installation procedure.<br />\n<strong>Abstract:</strong><br />\nThe aim of this document is to provide insights into installation procedures, key features and functionality and projected implementation effort of Icinga and Splunkstorm IT tools. Focus will be on presenting the most feasible implementation paths that surfaced once both software were well understood.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Evaluation of standard monitoring tools(including log analysis) for control systems at Cern", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Vintila, Vlad", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Varela Rodriguez, Fernando", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Zhang.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Abstract:</strong><br />\nTo inspire more people to contribute to science, and educate the public about science, two Citizen Science &quot;challenges&quot; were prepared during summer 2013: the CERN Summer Webfest 2013 and the Virtual LHC Challenge. The first part of this report summarizes how to organize a Webfest at CERN and the outcome of the CERN Summer Webfest 2013.The second part gives an introduction to the current state of the Virtual LHC Challenge: a development of the LHC@Home Test4Theory project planned to attract many unskilled volunteers. This work was supported by a grant from the EU Citizen Cyberlab project, with assistance from the Citizen Cyberscience Centre (CCC).</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Prepare for Citizen Science Challenges at CERN", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Zhang, Jiannan", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Segal, Ben", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Grey, Francois", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Skands, Peter", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Gold, Margaret", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERNopenlab_Report_Rocio_Rama.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nThe main goal of this project is to optimize the tcp buffer size to make more efficient the file transfers with FTS3. The library that has been implemented provides a way to calculate this providing a source and a destination. This way, whoever is transferring the files does not have to know anything about the logic of how calculate it. In this project, I have done a library to make easy the access to PerfSONAR&rsquo;s information between two hosts, calculating the optimized tcp buffer size and thereby to making more efficient the transfer of files. As part of my work, I have also tested the library to check if it actually improved the transfer throughput with tools as GridFTP and Globus.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Integration of Network Performance Monitoring Data at FTS3", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-08-31", 
      "creators": [
        {
          "name": "Rama Ballesteros, Roc\u00edo", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Salichos, Michail", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "\u00c1lvarez, Alejandro", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SASForum_2014_openlab_v1_0.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Big Data e Big Science", 
      "notes": "Presentata in italiano al SAS Forum 2014", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN, LHC, Data Analytics"
      ], 
      "publication_date": "2014-04-10", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p>Breve presentazione del ruolo dei dati nelle scoperte scientifiche, di come la comunita HEP gestisce la raccolta, analisi e distribuzione dei dati dell&#39;LHC e delle nuove sfide tecnologiche e professionali. Presentata in italiano al SAS Forum 2014</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-LassiKojo.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>There is a growing tendency by individuals to sign-up for public commercially operated</p>\n\n<p>cloud services without any involvement from the CERN IT department. The risks from</p>\n\n<p>these cloud services include issues around data security, transaction integrity, business</p>\n\n<p>continuity and regulatory compliance. This paper reports the most appropriate means to</p>\n\n<p>detect and measure usage of the most common commercial cloud services from devises</p>\n\n<p>on the CERN site.</p>\n\n<p>The results of the study summarise the scale, frequency and distribution of public</p>\n\n<p>commercially operated cloud services from devises on the CERN site.</p>", 
      "title": "Monitoring Commercial Cloud Service Providers", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Kojo, Lassi", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Lu\u0308ders, Stefan", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "FutureGov_2014_openlab_v1_0.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Big Data and Big Science", 
      "communities": [], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN, HEP, CERN openlab"
      ], 
      "publication_date": "2014-04-14", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p>Brief introduction to the challenges of big data in scientific research based on the work done by the HEP community at CERN and how the CERN openlab promotes collaboration among research institutes and industrial IT companies. Presented at the FutureGov 2014 conference in Singapore.</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-JosipDomsic.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>Within the project &ldquo;tracing and accounting of physical resources in CERN data centre&rdquo; a fully automated way of collecting information about physical resources has been designed and implemented. The implementation is split into three phases. In the first phase the information is collected from a number of different databases: hardware, network, elastic search, puppet, and foreman. In the second phase the collected information is stored into a Django database. The third part is a web application aggregates and displays the accumulated data.</p>", 
      "title": "Tracing and Accounting of Physical Resources in the Computer Centre", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Dom\u0161i\u0107, Josip", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Schwickerath, Ulrich ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_report_Fumero.pdf"
    ], 
    "metadata": {
      "description": "<p><strong>Project Specification:</strong><br />\nThis project concerns the parallel computing and vectorization field for Physics Computing at CERN. The document summarises the results and experience from vectorization activities and an initial evaluation of the CilkPlus technology with two different benchmarks from CERN.<br />\n<strong>Abstract:</strong><br />\nWith the release of the Intel Sandy Bridge processor, vectorization ceased to be a &ldquo;nice to have&rdquo; feature and became a necessity. This work is focused on optimization, running comparative measurements of available vectorization technologies currently under investigation by the CERN Concurrency Forum. In particular, the project involves an assessment of the limits of autovectorization in two compilers, an evaluation of CilkPlus as implemented in ICC/GCC and an evaluation of AVX/AVX2 benefits with respect to legacy SSE workloads.</p>", 
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Vectorization with Haswell and CilkPlus", 
      "publication_type": "report", 
      "upload_type": "publication", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Juan Jos\u00e9, Fumero Alfonso", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Andrzej, Nowak", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Innovation_20151126.pptx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Scientific Research is one of the strongest drivers behind innovation, but innovation cannot be fully exploited without providing a fertile ground for ideas to develop and mature. What can be done at CERN to maximize the human and technological assets that naturally gather together to work on the next frontiers of Physics research. The Innovation and Entrepreneurship Day is the first event co-organized by CERN openlab, the CERN KT group, IdeaSquare and Intel, a CERN openla industrial partner, to present ongoing activities, share expertise and collect ideas.</p>", 
      "title": "Innovation and Entrepreneurship Day", 
      "communities": [], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN openlab", 
        "Innovation", 
        "Entrepreneurship", 
        "Knowledge Transfer", 
        "IdeaSquare"
      ], 
      "publication_date": "2015-11-26", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Yigit_Demirag.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Vectorization Studies of Random Number Generators on Intel\u2019s Haswell Architecture", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Demirag, Yigit ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Wenzel, Sandro ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Funke, Daniel ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>This project concerns the field of vectorization for Computing in High&nbsp;Energy&nbsp;Physics at CERN,Geneva. This paper summarises the results and&nbsp;progress of&nbsp;vectorizing two newly proposed counter&nbsp;based random number&nbsp;generators on Intel&rsquo;s Haswell Architecture.</p>\n\n<p><strong>Abstract</strong>&nbsp;</p>\n\n<p>This project studies SIMD optimizing two different newly proposed random&nbsp;number generators on&nbsp;Intel&rsquo;s Haswell architecture with AVX2 instruction&nbsp;sets. AVX2 instruction set is necessary since&nbsp;many random number&nbsp;generators rely on 64-bit integer multiplication. In first phase,&nbsp;mathematical&nbsp;algorithms behind the random number generators are&nbsp;studied and the places where they can be vectorized&nbsp;are identified. Then all&nbsp;internal data structures of random number generators are transformed&nbsp;from&nbsp;Array of Struct to Struct of Array for better auto-vectorization.&nbsp;To achieve better results intrinsics&nbsp;are used via a high-level C++&nbsp;wrapping library. In second phase we performed benchmarks&nbsp;and studied&nbsp;the speed up obtained up to 1.57 times for Threefry CBRNG due to&nbsp;vectorization on&nbsp;Haswell.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Binathi_Bingi.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Integration of IT-DB Monitoring Tools into IT General Notification Infrastructure", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Bingi, Binathi", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Collados Polidura, David ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification </strong></p>\n\n<p>The goal of this openlab summer student project was to standardize the service notification and alarming system in the IT Database group. For this we need to integrate the IT General Notification Infrastructure (GNI) into some of our database services, like for instance, RACMon, Enterprise Manager, Syscontrol, RMAN, Database on Demand, and Storage Administrators&#39; tools. The objective was to make the GNI service our only mechanism to generate notifications and alarms (SMS, email, SNOW tickets) and as unique interface to visualize notifications.</p>\n\n<p><strong>Abstract </strong></p>\n\n<p>The IT Database group has independent monitoring tools/data and is immersed in a process of consolidating its monitoring infrastructure. The aim of this document is to provide insight into the way we achieved integration of GNI into our database services.</p>"
    }
  }, 
  {
    "files": [
      "CERN_openlab_Harry_Paul_Cutts.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Invenio Mobile App", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2014-09-01", 
      "creators": [
        {
          "name": "Cutts, Harry ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Kun\u010dar, Ji\u0159\u00ed ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Project Specification</strong></p>\n\n<p>The aim of this openlab summer student project is to enhance mobile user experience for Invenio digital library services. The project will use the Apache Cordova platform to build native Android and iOS applications. The application itself will be built using HTML5 and JavaScript technologies. An initial prototype of the application, targeting mostly search functionality, is available. The selected student will enrich existing functionality as well as address personal features related to tagging of resources or notifications about new publications of interest. The project will include server-side programming in Python to enrich REST API of the digital library platform.</p>\n\n<p><strong>Abstract</strong></p>\n\n<p>In this project, a mobile application is developed for the Invenio digital library system, using HTML5 with Apache Cordova. Alternative HTML5 technologies are compared and decisions justified. The features of a prototype are reimplemented with a view to improving performance, usability, and maintainability. OAuth2 authentication is implemented, and further work proposed.</p>"
    }
  }, 
  {
    "files": [
      "Huawei_IT_Leaders_openlab_v4.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "The Challenges of Scientific Computing", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "presentation", 
      "keywords": [
        "CERN", 
        "openlab", 
        "LHC", 
        "WLCG"
      ], 
      "publication_date": "2013-09-18", 
      "creators": [
        {
          "name": "Di Meglio, Alberto", 
          "affiliation": "CERN", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "This presentation describes a number of computing and data challenges experienced as part of the LHC and WLCG programs. It shows how these challenges are evolving also as part the CERN openlab partners' programs to follow the growing LHC requirements and discusses the importance of global collaborations and new service provisioning models in scientific research."
    }
  }, 
  {
    "files": [
      "Evaluation_of_Common_Interfaces_in_a_Multi-supplier_Cloud_Environment_for_Helix_Nebula.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "title": "Evaluation of Common Interfaces in a Multi-supplier Cloud Environment for Helix Nebula", 
      "publication_type": "report", 
      "communities": [
        {
          "identifier": "zenodo"
        }
      ], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2013-09-01", 
      "creators": [
        {
          "name": "Tsikiridis, Artem ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Cinquilli, Mattia ", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open", 
      "description": "<p><strong>Abstract</strong></p>\n\n<p>The Helix Nebula initiative is a partnership between leading European IT-intense scientific research organisations (CERN, EMBL and ESA) and leading IT cloud providers. Its goal is to form a federated Cloud Computing infrastructure that will satisfy the growing demand of scientists for computing power. The concept of the federated cloud requires a standard framework named BlueBox so that current and future cloud providers are able to smoothly interface their system to the existing multi-cloud infrastructure. Section one acts as an introduction to the reader, highlighting the importance of cloud computing in general and at CERN specifically, and provides a brief overview of the Helix Nebula initiative. Section two contains information about the functionality and performance of SlipStream, an interface that has been evaluated as a potential BlueBox solution. Section three contains the analysis of a de facto standard in cloud computing such as the EC2 interface, which is very useful for Helix Nebula and multi-cloud environments in general. Finally, in section 4, you may find listed the key conclusions about SlipStream, based on the evaluation that was carried out along with several other remarks about multi-cloud operations.&nbsp;</p>"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-SabrinaAmrouche.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Apache Mesos is a popular open source cluster manager for data centers and cloud environments, aimed at providing efficient resource isolation and sharing across distributed applications. Apache Mesos is used in multiple domains as it provides frameworks to run distributed applications for Big Data processing such as Hadoop, Spark and Storm, for batch scheduling like Chronos, data storage, PaaS and more.&nbsp;</p>\n\n<p>This report is about the evaluation of Apache Mesos in the context of data analytics and distributed applications. The evaluation consists mainly of the installation and configuration of an Apache Mesos cluster as well as the analysis of the performance and management of resources in a data analytics context.&nbsp;</p>", 
      "title": "Evaluation of Apache Mesos for Data Analytics", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Amrouche, Sabrina", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Martin Marquez, Manuel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Romero Marin, Antonio", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-AlexandreLuizBrisighelloFilho.docx"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p>Abstract</p>\n\n<p>With the newer versions, Docker is getting more and more stable and comes up with new features. Porting CMSSW workflows into it could make it easier to reproduce the execution on machines without access to the framework or to make a frozen benchmark that will always execute correctly.</p>\n\n<p>This report shows the main problems faced when generating the Docker container, the chosen solutions and some avoidable dead ends. In the end, the reader should be able to understand the main steps involved in achieving this objective.</p>\n\n<p>The result of the work is an command-line tool developed in Python named Morpheus. generating containers of CMSSW workflows, allowing usage of external tools and some customization. By using of the CMSSW environment installed in the host machine, it can generate working containers for the desired workflows. All the code have been documented and it should be easy to be extended.</p>", 
      "title": "Using Docker to Execute Offline Instances of CMSSW", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Brisighello Filho, Alexandre Luiz", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Szostek, Pawel", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }, 
  {
    "files": [
      "SummerStudentReport-MihaiPatrascoiu.pdf"
    ], 
    "metadata": {
      "license": {
        "title": "Creative Commons Attribution Share-Alike", 
        "url": "http://www.opendefinition.org/licenses/cc-by-sa", 
        "id": "cc-by-sa"
      }, 
      "description": "<p><strong>Abstract&nbsp;</strong></p>\n\n<p>The report presents a short overview on what OpenStack is, how and why is it used at CERN and also goes into detail about the OpenStack Manila component, a service that enables file based storage and file sharing within OpenStack virtual machines.&nbsp;</p>\n\n<p>OpenStack Manila is a relatively new OpenStack component, having started in 2012 and in 2014 it has reached the latest cycle of development, where it could still be found at the time of the report. The fundamental object Manila works with is the &lsquo;share&rsquo;, a unit of storage that can be accessed through the network simultaneously by multiple users. The scope of Manila is to provision shares in a &lsquo;Shares-as-a-Service&rsquo; fashion, allowing entrusted users to manage their own shares independently, without the need of any external assistance, such as from an admin.&nbsp;</p>\n\n<p>The scope of the project has been to experiment with this technology and assert its functionality in the context of the existing cloud at CERN. The report details the principal services and operation of OpenStack Manila, along with the most common used command lines. It also goes into detail about two ways in which Manila can be installed, either manually or by using a deployment automation tool. A look at the required configuration parameters is also presented.&nbsp;</p>\n\n<p>In the last part, the deployed Manila service at CERN is presented, together with the configuration options used for the backend, the part responsible with linking the Manila service to the actual storage platform used.&nbsp;</p>", 
      "title": "Manila \u2013 OpenStack File Sharing Service", 
      "publication_type": "report", 
      "communities": [], 
      "upload_type": "publication", 
      "keywords": [
        "CERN openlab Summer Student"
      ], 
      "publication_date": "2015-09-01", 
      "creators": [
        {
          "name": "Patrascoiu, Mihai ", 
          "affiliation": "CERN openlab Summer Student", 
          "orcid": "0000-0002-1694-233X"
        }, 
        {
          "name": "Leon, Jose Castro", 
          "affiliation": "Summer Student Supervisor", 
          "orcid": "0000-0002-1694-233X"
        }
      ], 
      "access_right": "open"
    }
  }
]